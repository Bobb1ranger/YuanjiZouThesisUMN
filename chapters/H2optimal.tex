\chapter{Distributed \(\mathcal{H}_2\) control}

\section{Gist of the Chapter}
\section{State-of-the-art on distributed \(\mathcal{H}_2\) optimal control}

Searching for stabilizing controllers with an arbitrary structure is not a convex problem in general~\cite{Tsitsiklis1985NP_decentralized}. Optimal controllers for an LTI plant in some structures can even be non-linear~\cite{ Witsenhausen1968ACI}. While the Youla parametrization enables us to search over stabilizing controllers convexly through closed-loop (CL) maps \cite{YoulaPar} when there is no structure, the structural constraints on the controllers may be projected into nonconvex constraints on the Youla Parameter, as their convexity is not preserved under linear fractional transformation (LFT).

Following the Youla parameterization approach, Voulgaris is the first to notice the usefulness of constructing a doubly coprime factorization (DCF) consistent with the desired structure, which enables a direct search for the Youla parameter \(Q\) within the same structured set \cite{Voulgaris2001convexity}. Other works identify several particular structures where consistently structured DCFs are accessible and establish convex control synthesis methods for such structures~\cite{Voulgaris2000nested, XinQ2004Nested, Bamieh2005CvxSI}. Later,~\cite{SanjayLQIsufficient} introduces the notion of Quadratic Invariance (QI) to unify all the structures for which one can search for the controllers convexly~\cite{LessardQI}. As part of their contribution, they establish the theoretical foundation for parameterizing all in-structure stabilizing controllers using a stable, structured, and stabilizing initial controller. However, obtaining such an initial controller is generally nontrivial.


To address this limitation, \cite{SabauVectorization} seeks to establish the classical Youla parameterization without relying on structured DCFs. In return, they introduce an affine constraint rather than a direct structural constraint as the price for eschewing structured DCFs:
\begin{equation}\label{eqn:strcst_0}
    H - U Q V \in \mathcal{S}.
\end{equation}
This constraint does not necessarily admit finite-impulse-response (FIR) solutions for the Youla parameter, which poses a major obstacle to its use in the controller synthesis, where FIR approximation is the standard practice for solving convex model-matching problems. Nevertheless, Lamperski and Doyle show that the constraint admits FIR solutions when the structural restrictions vanish after finitely many steps, which corresponds to strongly connected networks. They exploit this property to solve the optimal distributed \(\mathcal{H}_2\) control problem via a finite-dimensional convex optimization formulation \cite{Lamperski2015H2}.


A class of recent methods, e.g., SLP~\cite{SLSparametrization, wang2019SLS}, IOP~\cite{Furieri2019IOP}, and mixed parameterizations~\cite{Zheng2022SLP_IOP}, abandon the Youla parameterization approach. These methods over-parametrize the search spaces (not just $Q$) and enforce stabilization implicitly through infinite-dimensional equality constraints, which unfortunately are not guaranteed to have finite-dimensional feasible solutions. \cite{Matni2017SLStol} later addresses the tolerance of equality constraint violations in the SLP method. Overall, their synthesis formulation is sophisticated and leads to order inflation in the controller order. Fundamentally, these new parametrizations are equivalent to the Youla Parameterization~\cite{Zheng2021Equi_SLP_IOP, Tseng2021Equi_Par}.


The Youla operator state-space (YOSS) framework provides an alternative, over-parameterizing representation for all stabilizing controllers with a predefined structure~\cite{naghnaeian2019youla}. This approach introduces the notion of a generalized Luenberger observer with internal dynamics designed for networked systems. The paper establishes a distributed analogue of the Separation Principle, showing that distributed state estimation can be carried out independently and then used with “state-like” controllers to obtain the set of all output-feedback stabilizing controllers with a given structure. A key advantage of this approach is that the estimator and state-like feedback controller satisfy relaxed infinite-dimensional "inequalities", which admit finite-dimensional feasible solutions.


\section{Problem Formulation}\label{sec:ProbForm}
We formulate the networked optimal control problem following the generalized plant framework, requiring the plant \(P_{22}\) to be a networked system on the graph $\mathcal{G}^p=(\mathcal{V},\mathcal{A}^p)$.
\begin{opt}[Networked optimal control]\label{Prob::DistributedH2}
% $P$ is a generalized plant with the plant object \(P_{22}\) to be a networked system on graph $\mathcal{G}^p=(\mathcal{V},\mathcal{A}^p)$, i.e.
\begin{equation}\label{eqn::genplt_ss}
    P\colon 
    \begin{bmatrix} 
        w \\ u 
    \end{bmatrix}
    \mapsto
    \begin{bmatrix} 
        z \\ y 
    \end{bmatrix} = \left[
    \begin{array}{c:c}
    P_{11} & P_{12}\\
    \hdashline
    P_{21} & P_{22}
    \end{array}\right] =\left[
\begin{array}{c|cc}
    A & B_w & B_u \\
    \hline
    C_z & D_{zw} & D_{zu}\\
    C_y & D_{yw} & D_{yu}
\end{array}\right],
\end{equation}
\[
P_{22} = \left[
    \begin{array}{c|c}
    A & B_u\\
    \hline
    C_y & D_{yu}
    \end{array}\right]
    \in \mathfrak{S}(\mathcal{G}^p, \mathcal{P}_y, \mathcal{P}_u).
\]
where \(A\in S(\mathcal{A}^p,\mathcal{P}_x,\mathcal{P}_x)\), \(B_u\in S(I_n,\mathcal{P}_x,\mathcal{P}_u)\), \(C_y\in S(\mathcal{A}^p,\mathcal{P}_y,\mathcal{P}_x)\), \(D_{yu}\in S(I_n,\mathcal{P}_y,\mathcal{P}_u)\). \((A,B_u)\) is stabilizable, \((A,C_y)\) is detectable. Assumption~\ref{ass::statespace} is standard in the $\mathcal{H}_2$ setting, adopted here for simplicity of exposition.\footnote{In Assumption~\ref{ass::statespace}, (1) ensures that \(P_{21}\) and \(P_{12}\) have full normal row rank and normal column rank, respectively, whereas (2) ensures that they don't have transmission zeros on the unit circle. (1) and (2) together enable and simplify the spectral factorization of \(P_{21}\) and \(P_{12}\), see Appendix \ref{appsec::optH2}.}
\begin{assumption}\label{ass::statespace}
\begin{enumerate}
    \item \(D_{zu}\) is full column rank and \([D_{zu},D_{zu}^\perp]\) is unitary. \(D_{yw}\) is full row rank and \([D_{yw};D_{yw}^\perp]\) is unitary. \(D_{yu}=\mathbf{0}\).
    \item \(\left[\begin{array}{cc}
        A-e^{j\omega}  I & B_w \\
        C_y & D_{yw}
    \end{array}\right]\) has full row rank for \(\omega\in[0,2\pi)\).
     \(\left[\begin{array}{cc}
        A-e^{j\omega}  I & B_u \\
        C_z & D_{zu}
    \end{array}\right]\) has full column rank for \(\omega\in[0,2\pi)\).
\end{enumerate}
\end{assumption}
Given $\mathcal{G}^c=(\mathcal{V},\mathcal{A}^c)$,
% \footnote{\(\mathcal{A}^c\) decides the communication dependence among sub-controllers. More edges in \(\mathcal{G}^c\) enhance the controllability of the network plant, whereas \(\mathcal{A}^c = \mathbf{0}_n\) is the most complex problem, the fully decentralized control.}
find an internally stabilizing output feedback network distributed controller \(K\in {\cal K}_N \coloneqq \mathfrak{S}(\mathcal{G}^c, \mathcal{P}_u, \mathcal{P}_y)\)  that minimizes the following closed-loop \(\mathcal{H}_2\) cost:
\begin{equation}
    \mu_{\mathrm{dis},\mathcal{H}_2} \coloneqq  \displaystyle\min_{K\in {\cal K}_N-stabilizing}\ \|\Phi_{zw}(K)\|_{\mathcal{H}_2}^2, 
\end{equation}
where
\begin{equation}\label{eqn::Phi_K}
\Phi_{zw}(K) \coloneqq \lft(P,K) = P_{11}+P_{12} K(I-P_{22}K)^{-1} P_{21}.
\end{equation}
\end{opt}





\subsection{TFM Relaxation}
Problem 1 is generally challenging to solve in a bottom-up manner by optimizing \(\{K_i\}\) due to multiple feedback interactions between sub-components\footnote{
The full state-feedback case has well-established bottom-up synthesis approaches \cite{Lamperski2015StateFB, Shah2013Posets}. With full state access, one can directly measure interaction impact from other subsystems, simplifying the problem into decoupled LQRs.
}.
Instead, we follow the standard practice of relaxing the optimization domain into all stabilizing structured transfer function matrices that conform to the controller network, which means we search over the TFMs in \({\cal S}\coloneqq \mathfrak{T}(\mathcal{G}^c,\mathcal{P}_{u},\mathcal{P}_y)\)
(for notational simplicity, we will refer to this set as \(\mathcal{S}\)).
\footnote{Example~\ref{exp:4nodediamond} in section \ref{sec::numex} presents a case where this relaxation is strict.}

\begin{opt}[Structured optimal control]\label{Prob::networkoptcontrol}
Under the setting of Problem \ref{Prob::DistributedH2}, consider the following relaxation where we search over the set of structured transfer function matrices compatible with the network to minimize:
\begin{equation}
    \mu_{\mathrm{str}, \mathcal{H}_2} \coloneqq \underset{K - \text{stab and } K\in \mathcal{S}}{\min}\ \|\Phi_{zw}(K)\|_{\mathcal{H}_2}^2.
\end{equation}
\end{opt}
The above problem is still non-convex for two reasons: 1) \(\Phi_{zw}\) is a nonconvex function about \(K\) itself; 2) The set of all stabilizing controllers is not a convex set.


\subsection{Youla Parameterization}
% {\color{blue} Youla Parameterization is used to transform the non-convex cost function about \(K\) into a model-matching like cost function about Youla Parameter \(Q\) via a change of variables.}
The Youla-Kucera Parameterization is a well-established framework for resolving the non-convexity of both the linear fractional transformation and the stabilizing controller set by parametrizing all proper internally stabilizing controllers and recasting the objective function into a convex model-matching form with a stable variable \(Q\), often referred to as the Youla parameter~\cite{YoulaPar}.
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/DisCtrlfigure/YoulaParablkdiagram.png}
    \caption[Youla parameterization block diagram]{The block diagram of Youla parameterization. \(
    K_\mathrm{stab} = \lft(J_{YP},Q) = (Y_r - M_r Q) (X_r - N_r Q)^{-1}\). \(J_{YP}\) can be considered as an initial stabilizing controller. Setting \(Q = \mathbf{0}\) recovers the observer-based controller. A non-zero \(Q\) maps the output estimation error \(e = y - C_y \hat{x}\) to an additional input \(v\) that modifies the feedback behavior.}
    \label{fig:Youlapar}
\end{figure}
The central step for this parameterization is the \textbf{doubly co-prime factorization (DCF)} of \(P_{22}\)~\cite{ZhouRobustControl}. The DCF is given by eight stable transfer function matrices \(M_r,\ N_r,\ X_r,\ Y_r,\ M_l,\ N_l,\ X_l,\ Y_l\), which factorizes \(P_{22} = N_r M_r^{-1} = M_l^{-1} N_l\) and satisfies the Bézout identity:
\begin{equation}\label{eqn:Bezout}
    X_l M_r - Y_l N_r = I; \quad M_l X_r - N_l Y_r = I.
\end{equation}
As the stabilizable and detectable realization of the plant is available, we construct the DCF by selecting a pair of state-feedback gain and Luenberger observer \((F, L)\) such that \(A_F = A + B_u F\), \(A_L = A + L C_y\) are Schur.
\begin{equation}\label{DCF_r}
    \left[\begin{array}{cc}
    M_r & Y_r \\
    N_r & X_r
    \end{array}\right]
    =\left[
    \begin{array}{c|cc}
        A_F & B_u & -L \\
        \hline
        F & I & \mathbf{0}\\
        C_y & \mathbf{0} & I
    \end{array}\right]
\end{equation}
\begin{equation}\label{DCF_l}
    \left[\begin{array}{cc}
    X_l & -Y_l \\
    -N_l & M_l
    \end{array}\right]
    =\left[
    \begin{array}{c|cc}
        A_L & B_u & -L \\
        \hline
        -F & I & \mathbf{0}\\
        -C_y & \mathbf{0} & I
    \end{array}\right]
\end{equation}
By such construction, we have all stabilizing controller parametrized by:
\begin{equation}\label{eqn::allstabK}
\begin{split}
K_{\mathrm{stab}} & = \lft(J_{YP},Q) 
    = (Y_r - M_r Q) (X_r - N_r Q)^{-1}, \\
J_{YP} & = \begin{bmatrix}
    Y_r \\
    I
\end{bmatrix} X_r^{-1} 
\begin{bmatrix}
    I & N_r
\end{bmatrix} + 
\begin{bmatrix}
    \mathbf{0} & -M_r \\
    \mathbf{0} & \mathbf{0}
\end{bmatrix} \\
& = \left[
\begin{array}{c|cc}
  A +B_u F +L C_y&-L  & -B_u \\
  \hline
  F & \mathbf{0}_{n_u,n_y}& -I_{n_u}\\
  -C_y& I_{n_y} &\mathbf{0}_{n_y,n_u}
\end{array}
\right].
\end{split}
\end{equation}
The resulting CL \(\Phi_{zw}\) is given by:
\begin{equation}
\Phi_{zw} = \lft(P,K_\mathrm{stab}) = \lft(P,\lft(J_{YP},Q))\\
= \lft(\lft(P,J_{YP}),Q) = G_{11} -G_{12} Q G_{21}.    
\end{equation}
\(G_{11} = P_{11} + P_{12} Y_r M_l P_{21}\), \(G_{12} = P_{12} M_r\) and \(G_{21} = M_l P_{21}\) are all stable TFMs, see Appendix~\ref{appsec::optH2} for more information. After the change of variable in Youla Parameterization, Problem~\ref{Prob::networkoptcontrol} becomes the following optimization about Youla parameter \(Q\):
\begin{equation}\label{eqn::YoulaNonQI}
\begin{split}
    & \mu_{\mathrm{str}, \mathcal{H}_2} =   \min_{Q \in \mathcal{RH}_\infty^{n_u,n_y}} \quad 
        \|\, G_{11} - G_{12} Q G_{21} \,\|_{\mathcal{H}_2}^2,\\
    & \text{subject to } K_\mathrm{stab} = (Y_r - M_r Q) (X_r - N_r Q)^{-1} \in \mathcal{S}.
\end{split}
\end{equation}
Unfortunately, forcing \(K_\mathrm{stab} \in \mathcal{S}\) doesn't necessarily pose a convex constraint on \(Q\).
Early researchers noticed the significance of \textbf{structured DCF}, which means finding all the eight TFMs in~\eqref{eqn:Bezout} in \(\mathcal{S}\) 
\footnote{Finding \(F\in S(\mathcal{A}_c,\mathcal{P}_u,\mathcal{P}_x)\) and \(L\in S(I_n,\mathcal{P}_x,\mathcal{P}_y)\) is a straightforward method to obtain the structured DCF. However, this is hard in general. \cite{Vamsi_Realizable} provides a sufficient condition that ensures the existence of such \((F,L)\) pair.}.
The structured DCF simplifies the constraint~\eqref{eqn:mmstructconstr} into \(Q \in \mathcal{S}\), by exploiting the closure under addition and multiplication properties presented in Corollary~\ref{cor:cls}. They relied on structured DCF in those cases with special structures where structured DCFs are easily available to formulate convex synthesis. However, structured DCFs are hard to obtain in general.

\subsection{Quadratic Invariance}\label{subsec::QI}
Initially, quadratic invariance(QI) was proposed as a condition to unify the structures (w.r.t the plant) so that one can search over \(K_{\mathrm{stab}}\in \mathcal{S}\) by equivalently searching for CL \(\Phi \coloneqq \mathrm{feedback}(K_\mathrm{stab},P_{22}) = K_\mathrm{stab}( I - P_{22} K_\mathrm{stab})^{-1} \in \mathcal{S}\)~\cite{SanjayLQIsufficient}. Later, it's shown that QI is the necessary and sufficient condition that ensures \(K_\mathrm{stab} \in \mathcal{S}\) poses a convex constraint on \(Q\)~\cite{LessardQI, Sabau2011Vec}. The definition of QI is given as: 
\begin{defn}
${\cal S}$ is quadratic invariant w.r.t. $P_{22}$ if 
$$
KP_{22}K\subset {\cal S} ,\quad \forall K\in {\cal S} .
$$
\end{defn}
% When QI holds and the plant is stable or there is a stable stabilizing controller in \(\mathcal{S}\), \(\Phi\in \mathcal{S}\) can be a trivial structured DCF can be found for the plant.
\begin{thm}~\cite{Sabau2011Vec}\label{thm:struct_stab_cont_para}
Assume the set \(\mathcal{S}\) is QI under \(P_{22}\).
A controller \(K_\mathrm{stab} \in \mathcal{S}\) internally stabilizes \(P_{22}\), if and only if it is parameterized by a \(Q\) such that:
\begin{equation*}
\Phi \coloneqq \mathrm{feedback}(K_\mathrm{stab},P_{22}) = (Y_r -M_r Q)M_l \in \mathcal{S} 
,\ Q\in \mathcal{RH}_\infty.   
\end{equation*}
\end{thm}
\begin{rem}
The QI structure is highly related but not limited to network-distributed control problems. Some centralized structural constraints are also QI, e.g. \(\mathcal{O} \coloneqq \{K\vert\mathbf{1}^\top K =\mathbf{0}\}\).
\end{rem}
Theorem~\ref{thm:struct_stab_cont_para} provides a means to translate the structural constraint on the controller \(K\) into an equivalent condition requiring the closed-loop transfer matrix \(\Phi\) in the same set \(\mathcal{S}\). This equivalence allows the distributed optimal control problem to be reformulated as a convex model-matching problem in the single parameter \(Q\):
\begin{opt}\label{Prob::H2minafterpara}
\begin{equation}\label{eqn:mmcost}
    \mu_{\mathrm{str}, \mathcal{H}_2} = \underset{Q\in\mathcal{RH}_\infty}{\min}\ \|G_{11} - G_{12} Q G_{21}\|_{\mathcal{H}_2}^2 
\end{equation}
subject to
\begin{equation}\label{eqn:mmstructconstr}
    \Phi=(Y_r - M_r Q) M_l\in \mathcal{S}.
\end{equation}
\end{opt}
Conventional FIR approximation methods for solving model-matching problems are not applicable to Problem~\ref{Prob::H2minafterpara}, since the constraint~(\ref{eqn:mmstructconstr}) generally does not admit FIR solutions and tolerates no approximation error directly violates the structural constraints\footnote{When the graph is strongly connected, \(\Phi\) is a full block transfer function matrix with relative order constraints on some entries.}.

% ) (14-15) is an infinite dim convex optimization, (why in Banach instead of Hilbert is a minor point but takes the focus away). 2) Fir approximation is generally infeasible. 3) out of the blue, "huge efforts have been devoted to to further simplify the constraint...".
% Maybe you mean, (14-15) is an inf-dim convex problem in general, early work focused on the assumption that network-structured DCF can be found so that $\Phi\in {\cal S}$ simplifies to $Q\in{\cal S}$, and the problem becomes finite-dim. However, how to find such S-DCF in general is an open problem. We note that the classical finite-dim approximation by $Q$-FIR, is generally infeasible for (15). A main contribution of this paper, is to show how (14-15) can be exactly solved with finite dimensions. Even this line seems false or not linear. In reality, people did not know (15) at the time,or that they were trying to simplify (15). They assumed S-DCF, and directly? using QI got $Q\in S$, they did not have to go through $\Phi$ right? This is why this part, excluding (14-15) should be in the preliminary section, because it is a critical  review of the historical development }
% It essentially follows the intuition of first designing a networked stabilizing controller and then optimizing its behavior via a network-structured parameter.

\subsection{Stronger controller network assumption}
The optimization in (\ref{eqn::YoulaNonQI}) remains nonconvex when the QI condition doesn't hold. In this paper, we focus on scenarios where every interaction link in the plant dynamics is also available to the controller. Formally:
\begin{assumption}\label{ass::samegraph}
We assume \(\mathcal{A}^c \succeq \mathcal{A}^p\), where \(\mathcal{A}^p\) and \(\mathcal{A}^c\) denote the adjacency matrices of the plant and controller network graphs, respectively.
% \[
% a_{ij}^p = 1 \ \Rightarrow\ a_{ij}^c = 1, \quad \forall i,j.
% \]
\end{assumption}

Assumption~\ref{ass::samegraph} is central in our approach. Firstly, it sufficiently ensures QI and therefore the convexity of our solution approach, stated in Lemma ~\ref{lm:samegraphQI}. 

More importantly, we show in Theorem~\ref{thm:samegraphReal} that Assumption~\ref{ass::samegraph} also guarantees that every \(K_\mathrm{stab}\in \mathcal{S}\) admits an internally stabilizing distributed realization \(K_{\mathrm{dis}} \in {\cal K}_{N-\text{stab}}\) over the network. Consequently, there is no performance gap between Problem~\ref{Prob::DistributedH2} and Problem~\ref{Prob::H2minafterpara}, i.e. \(\mu_{\mathrm{dis}, \mathcal{H}_2} = \mu_{\mathrm{str}, \mathcal{H}_2}\). This equivalence doesn't generally hold under the QI condition alone, see Example~\ref{exp:4nodediamond} in Section~\ref{sec::numex}.
\begin{lemma}\label{lm:samegraphQI}
If Assumption~\ref{ass::samegraph} holds, \({\cal S}\) is QI w.r.t \(P_{22}\).
\end{lemma}
The proof is straightforward and therefore omitted.
% Because \(\mathcal{A}^c \succeq \mathcal{A}^p\), it follows that $\mathfrak{T}(\mathcal{G}^p,\mathcal{P}_o,\mathcal{P}_i)\subseteq \mathfrak{T}(\mathcal{G}^c,\mathcal{P}_o,\mathcal{P}_i)$ for any partition $\mathcal{P}_o,\mathcal{P}_i$. Therefore, $P_{22} \in \mathfrak{T}(\mathcal{G}^c,\mathcal{P}_y,\mathcal{P}_u)$. By Corollary~\ref{cor:cls}, this ensures that $KP_{22}K \in \mathfrak{T}(\mathcal{G}^c,\mathcal{P}_u,\mathcal{P}_y)$ for all $K \in \mathfrak{T}(\mathcal{G}^c,\mathcal{P}_u,\mathcal{P}_y)$.
\begin{thm}\label{thm:samegraphReal}~\cite{Gulnihal2018thesis}
Assume we are given the stabilizable and detectable network realization of \(P_{22}\) as the statement of Problem~\ref{Prob::DistributedH2}. If Assumption~\ref{ass::samegraph} holds and \(K_\mathrm{stab}\in \mathcal{S}\) internally stabilizes \(P_{22}\), there is \(K_\mathrm{dis}\in {\cal K}_N\) such that \(K_\mathrm{dis}\) internally stabilizes \(P_{22}\) and \(\mathrm{tf}(K_\mathrm{dis}) = K_\mathrm{stab}\). Specifically, consider the stable augmented plant \(\bar{P}_{22}\) and the augmented controller \(\bar{K}\):
\begin{equation*}
    \bar{P}_{22} = \left[\begin{array}{c|cc}
        \mathbf{0}_{n_x,n_x} & I_{n_x} & B_u \\
        \hline
        A & \mathbf{0}_{n_x,n_x} &\mathbf{0}_{n_x, n_u} \\
        A C_y & \mathbf{0}_{n_y,n_x} & \mathbf{0}_{n_y,n_u}
    \end{array} \right],\quad
    \bar{K} = \begin{bmatrix}
        I_{n_x} & \mathbf{0}_{n_x, n_y} \\
        \mathbf{0}_{n_u, n_x} & K_\mathrm{stab}
    \end{bmatrix}.
\end{equation*}
The interconnection \(\bar{\Phi} \coloneqq \mathrm{feedback}(\bar{K},\bar{P}_{22}) = \bar{K}(I - \bar{P}_{22} \bar{K})^{-1}\) is stable. Using the network realizations of \(\bar{\Phi}\), the stabilizable and detectable network realization \(K_{\mathrm{dis}}\) can be constructed as the interconnection:
\[
K_{\mathrm{dis}} = \begin{bmatrix}
    \mathbf{0} & I \end{bmatrix} \mathrm{feedback}(\bar{\Phi},- \bar{P}_{22})
    \begin{bmatrix}
    \mathbf{0} \\ I \end{bmatrix}
\]
\end{thm}


% \begin{thm}\label{thm:samegraphReal}~\cite{Gulnihal2018thesis}
% If Assumption~\ref{ass::samegraph} holds and \(K_\mathrm{stab}\in \mathcal{S}\) internally stabilizes \(P_{22}\), there is \(K_\mathrm{dis}\in {\cal K}_N\) such that \(K_\mathrm{dis}\) internally stabilizes \(P_{22}\) and \(\mathrm{tf}(K_\mathrm{dis}) = K_\mathrm{stab}\).
% \end{thm}
% \begin{proof}[Sketch of proof] Suppose \(K_{\mathrm{stab}}\) is an internal stabilizing controller for \(P_{22}\). Construct an augmented plant \(\bar{P}_{22} \in \mathfrak{S}(\mathcal{G}^p, \mathcal{P}_x + \mathcal{P}_y, \mathcal{P}_x+ \mathcal{P}_u)\) which is a stable networked system itself and is also stabilized by \(\bar{K}\), where
% \begin{equation*}
%     \bar{P}_{22} = \left[\begin{array}{c|cc}
%         \mathbf{0}_{n_x,n_x} & I_{n_x} & B_u \\
%         \hline
%         A & \mathbf{0}_{n_x,n_x} &\mathbf{0}_{n_x, n_u} \\
%         A C_y & \mathbf{0}_{n_y,n_x} & \mathbf{0}_{n_y,n_u}
%     \end{array} \right],\quad
%     \bar{K} = \begin{bmatrix}
%         I_{n_x} & \mathbf{0}_{n_x, n_y} \\
%         \mathbf{0}_{n_u, n_x} & K_{\mathrm{stab}}
%     \end{bmatrix}.
% \end{equation*}
% \(\mathrm{tf}(\bar{P}_{22})\in \mathfrak{T}(\mathcal{G}^p, \mathcal{P}_x + \mathcal{P}_y, \mathcal{P}_x+ \mathcal{P}_u)\)  and \(\bar{K} \in \mathfrak{T}(\mathcal{G}^c, \mathcal{P}_x + \mathcal{P}_u, \mathcal{P}_x+ \mathcal{P}_y)\), respectively.
% Furthermore, since \(\mathcal{A}^c \succeq \mathcal{A}^p\), \(\mathrm{tf}(\bar{P}_{22})\in \mathfrak{T}(\mathcal{G}^c, \mathcal{P}_x + \mathcal{P}_y, \mathcal{P}_x+ \mathcal{P}_u)\).
% The closed-loop \(\bar{\Phi} \coloneqq \mathrm{feedback}(\bar{K},\bar{P}_{22}) = \bar{K}(I - \bar{P}_{22} \bar{K})^{-1}\in \mathfrak{T}^s(\mathcal{G}^c, \mathcal{P}_x + \mathcal{P}_u, \mathcal{P}_x+ \mathcal{P}_y)\). 
% Follow \cite{Vamsi_Realizable} to construct a stabilizable and detectable network realization \(\bar{\Phi}_{\mathrm{dis}}\in \mathfrak{S}(\mathcal{G}^c, \mathcal{P}_x + \mathcal{P}_u, \mathcal{P}_x+ \mathcal{P}_y)\). Let,
% \begin{equation}\label{eqn:intmdlreal}
% \bar{K}_{\mathrm{dis}} = \mathrm{feedback}(\bar{\Phi}_{\mathrm{dis}}, - \bar{P}_{22}) 
% % = \bar{\Phi}_{\mathrm{dis}} (I + \bar{P}_{22}\bar{\Phi}_{\mathrm{dis}})^{-1}    
% \end{equation}
% \(\bar{K}_{\mathrm{dis}} \in \mathfrak{S}(\mathcal{G}^c, \mathcal{P}_x + \mathcal{P}_u, \mathcal{P}_x+ \mathcal{P}_y)\) is a networked system on \(\mathcal{G}^c\).
% \(\bar{K}_{\mathrm{dis}}\) internally stabilizes \(\bar{P}_{22}\) and \(\mathrm{tf}(\bar{K}_{\mathrm{dis}}) = \bar{K}\). Put
% \[
% K_{\mathrm{dis}} = \begin{bmatrix}
%     \mathbf{0}_{n_u,n_x} & I_{n_u}
% \end{bmatrix} \bar{K}_{\mathrm{dis}}
% \begin{bmatrix}
%     \mathbf{0}_{n_x,n_y} \\ I_{n_y}
% \end{bmatrix}.
% \]
% \({K}_{\mathrm{dis}} \in \mathfrak{S}(\mathcal{G}^c, \mathcal{P}_u, \mathcal{P}_y)\) is a networked system on \(\mathcal{G}^c\), internally stabilizes \(P_{22}\) and \(\mathrm{tf}(\bar{K}_{\mathrm{dis}}) = K_{\mathrm{stab}}\).
% \end{proof}
% \begin{rem}
% Example~\ref{exp:4nodediamond} gives a case where QI holds, but the lack of Assumption~\ref{ass::samegraph} prevents distributed implementation despite structural conformity.
% \end{rem}
\begin{rem}
Since replicating stable poles preserves internal stability, constructing stable network dynamics is more manageable. Consequently, prior studies have relied on the stabilized closed-loop to realize networked controllers on networks~\cite{wang2019SLS, Gulnihal2018thesis, Rantzer2019Netimpl}. In this work, we adopt the realization approach of~\cite{Gulnihal2018thesis}. Notably, all existing network realization methods require the network realization of \(P_{22}\); developing realizations without this information remains an open problem.
\end{rem}

\section{Main results}\label{sec:Mainresult}


% We demonstrate that a Youla parameter subject to implicit infinite-dimensional sparsity constraints (\ref{eqn:mmstructconstr}) cannot be approximated by truncation over a finite horizon in general. 
% To address this, we provide an algebraic approach to generate infinite impulse response solutions of Youla Parameters in finite computations. We also offer a criterion for deciding the existence of solutions to (\ref{eqn:mmstructconstr}). 
Algorithm~\ref{alg::optcontroller} outlines the key steps for solving Problem~\ref{Prob::H2minafterpara}, covering problem transformation, feasibility verification, and exact solution construction. We prove that this algorithm works if and only if there is a stabilizing controller in the structure set \(\mathcal{S}\) by studying the time-domain interpretation of the constraint~\eqref{eqn:mmstructconstr}.
These results complete and substantiate our earlier work \cite{Yuanji2024disH2, Yuanji2024spar}. 

\begin{algorithm}
\caption{Optimal structured controller solution}\label{alg::optcontroller}
\begin{algorithmic}[1]
\State Solve DAREs for centralized \(\mathcal{H}_2\) controller, see \eqref{eqn::centralizedH2contParas} in the appendix. Use spectral factorization \(F,L\) to establish Youla Parameterization. Problem~\ref{Prob::H2minafterpara} becomes Problem~\ref{Prob::H2min_infHorQuad}. 
\State Vectorize cost and constraint in Problem~\ref{Prob::H2min_infHorQuad}. 
Find the orthonormal basis \(E_0,\hdots,E_m\) of the vectorized support \(\vc(\supp(\Phi[i]))\) that equivalently enforces \(\Phi \in \mathcal{S}\). Follow \eqref{eqn::ss::vecmat} and Lemma~\ref{lemma:redsys} to formulate Problem~\ref{Prob::H2min_ssqp}.
\If{\((A_r,B_r^m)\) is stabilizable}
\State Solve Problem~\ref{Prob::H2min_ssqp} by an extra DARE~\eqref{eqn:vecDARE} and a Riccati backward Recursion \eqref{eqn::backrec}, \eqref{eqn::optu0}.
\State Iteratively recover the optimal sequence \(\{q^*\}\) by \eqref{eqn::YPrecovery1}. Use \eqref{eqn::YPrecovery2} to construct the optimal \(\vc(Q_\mathrm{opt})\), inverse vectorization to find \(Q_\mathrm{opt}\). Find \(K_\mathrm{str, opt} \in \mathcal{S}\) by \eqref{eqn::Krecovery}.
\Else
\State No \(K_{\mathrm{stab}}\) in \(\mathcal{S}\). (Problems~\ref{Prob::H2minafterpara},~\ref{Prob::H2min_infHorQuad},~\ref{Prob::H2min_ssqp} are infeasible).
\EndIf
\end{algorithmic}
* Note that this synthesis approach is valid for all QI structures even without Assumption~\ref{ass::samegraph}.
\end{algorithm}


\subsection{Youla parameterization by spectral factorization}
Since the hardness of structured DCF, we use an alternative method that enjoys other algebraic convenience, inspired by \cite{Lamperski2015H2}. We formulate the DCF using the LQR state-feedback gain \(F\) and Kalman gain \(L\) that achieves the spectral factorization of \(P_{12}\) and \(P_{21}\). Such selection of \(F,L\) brings us several algebraic benefits from classical \(\mathcal{H}_2\) control theory:
\begin{enumerate}
    \item In \eqref{eqn::allstabK}, \(K_{\mathcal{H}_2}= \mathcal{F}_l(J_{YP}, R_0)= (Y_r - M_r R_0) (X_r - N_r R_0)^{-1}\) is the centralized \(\mathcal{H}_2\) controller, \(R_0\) is a static gain term given in (\ref{eqn:YP_R0}).
    \item \(G_{12} = P_{12} M_r\) and \(G_{21} = P_{21} M_l\) satisfy \(G_{12}^{\sim} G_{12} =\Gamma_b\) and \(G_{21} G_{21}^{\sim} =\Gamma_c\), where \(\Gamma_b ,\Gamma_c\) are all positive definite matrices.
    \item \(G_{12}^\sim G_{11}^0 G_{21}^\sim \in \mathcal{RH}_2^\perp\), where \(G_{11}^0 \coloneqq G_{11} -G_{12} R_0 G_{21}\).
\end{enumerate}
As a result, the model-matching cost in Problem \ref{Prob::H2minafterpara} can be reformulated as a matrix weighted norm minimization problem on the Youla parameter in Problem \ref{Prob::H2min_infHorQuad}. Details are in the Appendix~\ref{appsec::optH2}.
\begin{opt}\label{Prob::H2min_infHorQuad}
\(\mu_{\mathrm{str}, \mathcal{H}_2} = \|G_{11}^0\|_2^2 + J_\mathcal{S}\)
\begin{equation}
     J_\mathcal{S} \coloneqq \underset{Q\in\mathcal{RH}_\infty}{\min} \|\Gamma_b^{\frac{1}{2}}(Q-R_0) \Gamma_c^{\frac{1}{2}}\|_{\mathcal{H}_2}^2  
\end{equation}
subject to \(\quad\Phi = (Y_r - M_r Q) M_l\in \mathcal{S}\). 
\end{opt}
Problem~\ref{Prob::H2min_infHorQuad} suggests that the structured \(\mathcal{H}_2\) cost is essentially equivalent to the cost penalty \(J_\mathcal{S}\) caused by the structural constraints on~\eqref{eqn:mmstructconstr}.









\subsection{Time domain interpretation}
We transform Problem~\ref{Prob::H2min_infHorQuad} into a time-domain interpretation for following two reasons:
\begin{enumerate}
    \item Since spectral factorization expresses the \(\mathcal{H}_2\) cost as a matrix-weighted norm of the Youla parameter \(Q\), it is natural to invoke Parseval’s theorem to convert the frequency-domain \(\mathcal{H}_2\) norm into an \(\ell_2\)-norm of the unilateral time-domain impulse response of \(Q\).
    \item The structural constraints including sparsity and element-wise relative orders are easier to impose on \(\Phi\)'s unilateral impulse response. 
\end{enumerate}
In time-domain, the cost to be minimized becomes an \(\ell_2\) norm of a sequence:
\begin{equation*}
\begin{split}
    & \|\Gamma_b^{\frac{1}{2}}(Q-R_0) \Gamma_c^{\frac{1}{2}}\|_{\mathcal{H}_2}^2 = \sum_{i = 0}^\infty \mathrm{trace}(V[i]^\top V[i]), \\
    & V[i] = \left\{\begin{array}{cc}
        \Gamma_b^{\frac{1}{2}}(Q[0]-R_0) \Gamma_c^{\frac{1}{2}} & i = 0\\
        \Gamma_b^{\frac{1}{2}}Q[i] \Gamma_c^{\frac{1}{2}} & i \geq 1
    \end{array}\right. .
\end{split}  
\end{equation*}
The structural constraints can be enforced by a time-dependent support pattern on the impulse responses of \(\Phi\), given as in (\ref{eqn::time_support}).
\(\Phi\in \mathcal{S} = \mathfrak{T}(\mathcal{G}^c,\mathcal{P}_u,\mathcal{P}_y)\) is supported as:
\begin{equation}\label{eqn::time_support}
\left[\supp(\Phi[t])\right]_{ij} = \left\{\begin{array}{c}
    \mathbf{1}_{\mathcal{P}_u(i)\times \mathcal{P}_y(j)},\ t \geq \bar{w}_{ij} \text{ or } i = j\\
    \mathbf{0}_{\mathcal{P}_u(i)\times \mathcal{P}_y(j)},\ \text{Otherwise}
\end{array}\right. .
\end{equation}
For illustration, we take Example~\ref{exp::3nodesys} again and assume all the subsystems are SISO without losing generality, namely \(\mathcal{P}_u=\mathcal{P}_y =[1,1,1]\). The time-domain responses of \(\Phi\) are:
\begin{equation*}
\Phi[0] \in \left[
\begin{array}{ccc}
\mathbb{R} & 0 & 0\\
0 & \mathbb{R} & 0\\
0 & 0 & \mathbb{R}\\
\end{array}
\right];\ 
\Phi[1] \in \left[
\begin{array}{ccc}
\mathbb{R} & \mathbb{R} & 0\\
\mathbb{R} & \mathbb{R} & 0\\
\mathbb{R} & 0 & \mathbb{R}\\
\end{array}
\right];\ 
\end{equation*}
\begin{equation*}
\Phi[2],\ \Phi[3],\hdots \in \left[
\begin{array}{ccc}
\mathbb{R} & \mathbb{R} & 0\\
\mathbb{R} & \mathbb{R} & 0\\
\mathbb{R} & \mathbb{R} & \mathbb{R}\\
\end{array}
\right].
\end{equation*} 
% (\ref{eqn:mmstructconstr}) implies:

% \begin{equation}
% \left\{\begin{array}{c}
%     \left[(Y_r - M_r Q) M_l\right]_{ij} = 0, \bar{w}_{ij} = \infty\\
%     z^{\bar{w}_{ij}}\left[(Y_r - M_r Q) M_l\right]_{ij} \in \mathcal{R}_p, \bar{w}_{ij} < \infty
% \end{array}\right. . 
% \end{equation}

% We stress that sparsity is some form of orthogonality that a bunch of Lagrangian multipliers can handle, either in the frequency domain or the time domain. The relative orders at corresponding entries represent delays. To the best of our knowledge, relative orders can only be enforced on the Laurent series of the complex function, which is more relevant to time-domain interpretation.




% Therefore, it is natural to set up separate steps and treatments for sparsity and delay constraints.
% We introduce the following subspace based on \(\mathcal{S}\):

% \begin{equation}
%     \mathcal{S}_{\mathrm{spar}} = \mathfrak{T}(\mathcal{G}_0,\mathcal{P}_u,\mathcal{P}_y)
% \end{equation}
% A closer observation of the optimal \(\Phi^o\) can be

% We still look at the example in Fig. \ref{fig:Vamsi_net} for illustration, assuming each edge corresponds to a one-step delay.
% \(\mathfrak{T}(\mathcal{G},\mathcal{P}_u,\mathcal{P}_y)\) can be collectively written as (\ref{eqn::TFMconstr1}).

\subsection{Vectorization}
Vectorizing the Youla parameter $Q$ and the closed-loop map $\Phi$ allows us to transform the equality relationship in~(\ref{eqn:mmstructconstr}) into an equivalent set of state-space equations that relate their unilateral impulse responses, as stated in Theorem~\ref{thm:vectimeresp}.
\begin{thm}\label{thm:vectimeresp}
For any \(Q, \Phi\in \mathcal{RH}_\infty\) that satisfies: \(\Phi = (Y_r - M_r Q) M_l\), their vectorized impulse responses \(q[i] =\vc(Q[i])\) and \(\phi[i] =\vc(\Phi[i])\) satisfy the following state-space equations with a zero initial condition (\(\eta[0]=\mathbf{0}\)):
\begin{equation}\label{eqn::ss::vecPhitovecQ}
\begin{split}
    \eta[i+1] &=A_v \eta[i] +B_v \phi[i] +b_0 \delta; \\
    q[i] &= C_v \eta[i] +D_v \phi[i].
\end{split}
\end{equation}
\(\delta\) denotes the unit impulse signal applied at time \(i =0\). The matrices are given by:
\begin{equation}\label{eqn::ss::vecmat} 
\begin{split}
& \left[\begin{array}{c|c:c}
    A_v & b_0 & B_v \\
    \hline
    C_v & d_0 & D_v
\end{array}\right]   \\
& \coloneqq 
\left[
\begin{array}{cc|c:c}
I_{n_y}\otimes A &  \mathbf{0}_{n_y n_x,n_x n_u} & \mathbf{0}_{n_x n_y,1} & I_{n_y} \otimes B_u\\
-C_y^\top \otimes F & A^\top\otimes I_{n_u} & \vc(F) & C_y^\top \otimes I_{n_u} \\
\hline
I_{n_y} \otimes F & L^\top \otimes I_{n_u} & \mathbf{0}_{n_u n_y,0} & -I_{n_u n_y} 
\end{array}\right].
\end{split}
\end{equation} 
Furthermore, sequences \(\eta,q,\phi\) are all in \(\ell_2\). For later use, we succinctly write \eqref{eqn::ss::vecPhitovecQ} as \(q = \mathcal{O}(\phi)\), where \(\mathcal{O} : \left( \mathbb{N} \to \mathbb{R}^{n_u n_y , 1} \right) \to \left( \mathbb{N} \to \mathbb{R}^{n_u n_y , 1} \right)\).

% map , characterized in a state-space form :

\end{thm}
See Appendix~\ref{sec:app_vecssana} for the proof.
\begin{rem}\label{rem::rationalsoln1} \((A_v,B_v)\) is stabilizable and \((A_v,C_v)\) is detectable because \(A_v+B_v C_v\) is Schur from construction:
\begin{equation}
    A_v+B_v C_v =  \left[
    \begin{array}{cc}
    I_{n_y}\otimes A_F &  L^\top\otimes B_u \\
    \mathbf{0}_{n_x n_u,n_x n_y} & A_L^\top\otimes I_{n_u} \\
    \end{array}\right].
\end{equation}  
\end{rem}


After vectorization, the time-varying support in~\eqref{eqn::time_support} is replaced by an operator $\mathbf{E}\colon u \mapsto \phi$. $\phi[i] = E_i u[i]$, where $u[i]$ is free and $E_i$ is an orthonormal basis of the vectorized support pattern $\vc(\supp(\Phi[i]))$. Specifically, each $E_i$ consists of standard unit vectors in the directions where $\vc(\Phi[i])$ can be nonzero\footnote{This formulation readily extends to MIMO subsystems and edges with multiple delays.}. The vector space $\mathrm{span}(E_i)$ is monotonically growing since each sub-controller gains access to more information from additional subsystems over time. After finite steps, $E_i$ stabilizes because every sub-controller will have received information from all connected subsystems. In math:
\begin{equation*}\label{eqn::Ei_growth}
    \mathrm{span}(E_0)\subset\mathrm{span}(E_1)\hdots\subset\mathrm{span}(E_m) = \mathrm{span}(E_{m + 1}) = \hdots .
\end{equation*}
After incorporating the structure constraint, it becomes to finding the solution pairs \((q,u)\) to \(q = \mathcal{O}(\mathbf{E} u)\).
% \begin{equation}\label{eqn::strct_vectf}
%     q = \vc(M_r^{-1}Y_r)-\left({M_l}^{-\top}\otimes {M_r}^{-1} \right) \mathbf{E} u.
% \end{equation}
Or equivalently:
\begin{equation}\label{eqn:strct_vecss}
\begin{split}
    \eta[i+1] &=A_v \eta[i] +B_v E_i u[i] +b_0 \delta,\ \eta[0]=\mathbf{0};\ \\
    q[i] &= C_v \eta[i] +D_v E_i u[i].
\end{split}
\end{equation}
\(E_i\) may erase specific input channels and make the state-space not stabilizable potentially. 

\begin{rem}
By optimizing over \(\ell_2\) sequences \(q\) and \(u\) that satisfy \eqref{eqn:strct_vecss}, we slightly relax the search space, as an arbitrary \(\ell_2\) sequence does not necessarily correspond to the impulse response of an operator in \(\mathcal{RH}_\infty\).
\end{rem}
\begin{rem} The vectorized state-space is where the structural constraint can be imposed more easily. However, the presence of sparsity constraints (\(\mathbf{E}\)) induces changes to an otherwise stabilizable system. The lack of stabilizability arises as a potential concern. It needs to be carefully studied as it can be artificial but intrinsic in the state-space expansion of the vectorizations, together with the limitations of the structured control actions.

The following subsection contains the core of this analysis and the paper's main technical contribution, which enables the safe and lossless removal of fictitious obstacles to stabilization.
\end{rem}

On the other side, letting \(v[i] = \vc(V[i])\), the cost term in Problem~\ref{Prob::H2min_infHorQuad} is equivalently transformed into
\begin{equation}\label{eqn:veccost}
\begin{split}
    & \|\Gamma_b^{\frac{1}{2}}(Q-R_0) \Gamma_c^{\frac{1}{2}}\|_{\mathcal{H}_2}^2   = \sum_{i=0}^{\infty} v[i]^\top v[i], \\
    & v[i] = \begin{cases}
        \Gamma^{\frac{1}{2}}(q[0]-\vc(R_0)) & i = 0\\
        \Gamma^{\frac{1}{2}} q[i] & i \geq 1
    \end{cases},\quad \Gamma \doteq \Gamma_c \otimes \Gamma_b,
\end{split}
\end{equation}
leveraging that vectorization preserves inner product.

% We employ the idea from \cite{Lamperski2015H2} that converts the equality relationship, captured in (\ref{eqn:mmstructconstr}), between two rational TFMs, Youla parameter \(Q\) and closed-loop \(\Phi\), into a constraint of their vectorized unilateral time-domain impulse responses. As the search will be done in the time domain, we take an inversion of (\ref{eqn:mmstructconstr}) for better explanation.




% \subsection{Enforcing the structure}
% Since an LTI dynamical system can be fully characterized by its infinite impulse response (IIR), these constraints can be enforced by specifying the support pattern of IIR.  


% Assume now all the subsystems are SISO and that each edge corresponds to a one-step delay. 


% The time-varying support pattern is replaced by a deterministic time-varying linear operator \(\mathbf{E}\) after vectorization. \(E_i\) is the orthonormal basis of the vectorized support pattern \(\vc(\supp(\Phi[i]))\). It consists of the standard unit vectors in the directions that \(\vc(\Phi[i])\) can be non-zero. The essence remains when the subsystems are MIMO and edges have multiple delays.

% We define the operator \(\mathbf{E} \colon u \mapsto \phi\) by \(\phi[i] = E_i u[i]\), where \(u[i]\) is free. The multiplier sequence \(\{E_i\}\) is monotonically growing because each sub-controller can access more information from further sub-plants after more steps. After a finite number of steps, \(E_i\) stabilizes, as each sub-controller has received information from all connected subsystems. In math:


\subsection{The structural constraint analysis}
In the state-space~\eqref{eqn:strct_vecss}, the initial condition is zero, and the impulse signal together with \(u\) are the system inputs driving the state dynamics. It's natural to find a coordinate transformation that extracts and removes state directions that remain zero. 
\begin{lemma}\label{lemma:redsys}
Let \(T_r\) be the orthonormal basis of the reachable subspace of \((A_v,[B_v E_m,b_0])\), and chose \(T_r^\perp\) to make \(\begin{bmatrix} T_r & T_r^\perp\end{bmatrix}\) an orthonormal matrix. Let \(T_l = T_r^\top\) and \(T_l^\perp = (T_r^\perp)^\top\). Put \(A_r = T_l A_v T_r\), \(C_r = C_v T_l\), and \(b_r = T_l b_0\). For each \(i\leq m\), let \(B_r^i = T_l B_v E_i,\ D_i = D_v E_i\). By such construction, we have \(T_l^\perp \eta[i] \equiv 0\) in \eqref{eqn:strct_vecss} and the state-space:
\begin{equation}\label{eqn::ss::lemmared_xi}
\begin{split}
    \xi[i+1] & =A_r \xi[i] + B_r^i u[i] + b_r \delta; \xi[0] =\mathbf{0};\\
    q[i] &= C_r \xi[i] +D_i u[i]
\end{split}
\end{equation}
has identical input-output response as \eqref{eqn:strct_vecss}. 
\end{lemma}
\begin{proof}
See Appendix~\ref{sec:app_vecssana} for proof.    
\end{proof}
Combining with \eqref{eqn:veccost}, the minimal dynamical system capturing the algebraic relationship between the impulse responses \(\phi = \mathbf{E} u \) and \(q\) in \eqref{eqn::ss::lemmared_xi} enables us to recast the \(\mathcal{H}_2\) Problem~\ref{Prob::H2minafterpara} into an open-loop \(\ell_2\) norm minimization problem: 
\begin{opt}\label{Prob::H2min_ssqp}
\(\mu_{\mathrm{str}, \mathcal{H}_2} = \|G_{11}^0\|_2^2 + J_\mathcal{S}\),
\begin{equation}
     J_\mathcal{S} = \underset{u\in\ell_2, v\in\ell_2}{\min} \sum_{i=0}^{\infty} v[i]^\top v[i]\\
\end{equation}
subject to
\begin{equation}\label{eqn::ss::reduced2norm}
\begin{split}
    \zeta[i+1] &=A_r \zeta[i] + B_r^i u[i] + b_r \delta; \ \zeta[0] =\mathbf{0}\\
    v[i] &= \Gamma^{\frac{1}{2}} C_r \zeta[i] + \Gamma^{\frac{1}{2}} D_i u[i] -\Gamma^{\frac{1}{2}}\vc(R_0)\delta,\\
\end{split}
\end{equation}
\end{opt}
Note that \(B_r^i = B_r^m = T_l B_v E_m, \forall i \geq m\).
Problem~\ref{Prob::H2min_ssqp} has a well-established closed-form solution via a dynamic programming approach when \((A_r, B_r^m)\) is stabilizable. 
However, it's still unknown when and how this stabilizability is guaranteed. We introduce Theorem~\ref{thm::vecconstraintsoln} and Lemma~\ref{lm:delay_stage}, which jointly ensure that \((A_r, B_r^m)\) is stabilizable if and only there is pairs \((q,u) \in \ell_2\) such that \eqref{eqn:strct_vecss} holds.

Before that, we revisit some concepts of open-loop stabilizability and asymptotic behavior, with primary reference to \cite{trentelman2012control}.
\begin{defn}
Given a discrete-time system defined as
\[
x[k+1] = A x[k] + B u[k], \quad x[0] \coloneqq x_0,
\]
where \( x[k] \in \mathcal{X} = \mathbb{R}^n \), \( A \in \mathbb{R}^{n \times n}\).
The \textbf{stabilizable subspace} of the pair \( (A, B) \), denoted by \(\mathcal{X}_{stab}(A, B) \) (or in brief \(\mathcal{X}_{stab}\)), is defined as
\begin{equation*}
\begin{aligned}
\mathcal{X}_{\mathrm{stab}}(A, B) \coloneqq \bigl\{ x_0 \in \mathbb{R}^n \mid \ & \exists\, u[k] \text{ (a Bohl function) s.t. } \\
& x_u[k; x_0] \in \ell_2 \bigr\},
\end{aligned}
\end{equation*}
where \( x_u[k; x_0] \) denotes the state trajectory under input \( u \) starting from \(x_0\).
\end{defn}

Given an arbitrary square matrix \(A\), \(\psi_A(\lambda)\) denotes the monic characteristic polynomial of \(A\), and it can be factorized into \(\psi_A = \psi_A^s \cdot \psi_A^{ns}\), where \(\psi_A^s\) have all zeros inside the unit circle and \(\psi_A^{ns}\) contains all anti-stable zeros.

We define the following subspaces of \(\mathcal{X}\), which are both \(A\)-invariant,
Reachable subspace:
\[\mathcal{R}_{A,B} \coloneqq \im([B,AB,A^2 B,\hdots, A^{n-1} B]),\]
and stable subspace, which is irrelevant to \(B\): \(\mathcal{X}_A^s \coloneqq \ker(\psi_A^s(A))\).
The stable subspace \(\mathcal{X}_A^s\) is spanned by the (generalized) eigenvectors of all stable (i.e. $|\lambda|<1$) modes.
\begin{lemma}
    \(\mathcal{X}_{stab} = \mathcal{R}_{A,B} + \mathcal{X}_A^s\)
\end{lemma}
\begin{proof}
    Proof is in the book \cite{trentelman2012control}, Chapter 4, Page 92.
\end{proof}

\begin{lemma}\label{lm:poly_nonzero_inner_product}
Let \( A \in \mathbb{C}^{n \times n} \), and let \( v\in \mathbb{C}^n, g\in  \mathbb{C}^n\), with a fixed scalar \( \lambda_0 \in \mathbb{C} \). Suppose:
\( v^\top g \neq 0 \), and \( v^\top (\lambda_0 I - A) A^k g = 0 \) for all integers \( k \geq 0 \).
Then for any polynomial \( p(\lambda) \in \mathbb{C}[\lambda] \) such that \( p(\lambda_0) \neq 0 \), \(v^\top p(A) g \neq 0\).
\end{lemma}

Theorem~\ref{thm::vecconstraintsoln} considers a modified state-space from \eqref{eqn:strct_vecss} that includes only sparsity constraints from \(\mathcal{S}\) by replacing \(E_i\) with \(E_m\) for \(i = 0, \hdots m - 1\) and shows the modified state-space has \(\ell_2\) input-output solution if and only if the reduced pair \((A_r, B_r^m)\) is stabilizable. Besides, it also provides a method to construct solutions of input and output sequences that are produced by the impulse responses of rational TFMs in \(\mathcal{RH}_\infty\).  
\begin{thm}\label{thm::vecconstraintsoln}

Consider the affine operator 
\(\bar{\mathcal{O}} : \left( \mathbb{N} \to \mathbb{R}^{n_u n_y, 1} \right) \to \left( \mathbb{N} \to \mathbb{R}^{n_u n_y, 1} \right)\), characterized in a zero initial condition (\(x[0] =\mathbf{0}\)) iterative state-space form:
\begin{equation}\label{eqn:strct_vecss_m}
\begin{split}
    \bar{\mathcal{O}} \colon x[i+1] &=A_v x[i] + B_v E_m u[i] + b_0 \delta;\ \\
    y[i] &= C_v x[i] + D_v E_m u[i].
\end{split}
\end{equation}
The following statements are equivalent:
\begin{enumerate}\label{enum:maintheorem}
    \item \label{enuitem1} There exists a pair of \((y,u) \in \ell_2\) such that \(y = \bar{\mathcal{O}}(u)\).
    \item \label{enuitem2} \(b\) in the stabilizable subspace of $(A,B)$, denoted by \(\mathcal{X}_{stab}\).
    \item \label{enuitem3} Construct \(T_r, T_r^\perp, T_l, T_l^\perp\) as in Lemma~\ref{lemma:redsys}, the pair \((A_r ,B_r) = (T_l A_v T_r, T_l B_v E_m)\) is stabilizable.
\end{enumerate}
\end{thm}
% It is important to note that the state-space matrices in Theorem~\ref{thm::vecconstraintsoln} do not correspond to those of the plant but are introduced solely to simplify the notation in the proof.
% % Theorem~\ref{thm::vecconstraintsoln} primarily serves to justify our subsequent treatment of (\ref{eqn::QPhirelation}). 
% % \(H\) and \(M\) will be replaced by
% % \[
% % H = \vc(M_r^{-1}Y_r),\quad M = ({M_l}^{-\top}\otimes {M_r}^{-1})\cdot E
% % \]

\begin{proof}
We provide the proof in a cycle. For the notation simplicity in the proof, we abbreviate:
\[
\left[\begin{array}{c|c:c}
    A_v & b_0 & B_v E_m\\
    \hline
    C_v & d_0 & D_v E_m
\end{array}\right] \longrightarrow 
\left[\begin{array}{c|c:c}
    A & b & B\\
    \hline
    C & d & D
\end{array}\right].
\]

Proof of \(\ref{enuitem1} \Rightarrow\ref{enuitem2}\):
Since there is \(u\in\ell_2\) such that \(y = \mathcal{O}(u)\in \ell_2\)
Because of the detectability of \((A,C)\), the states \(x\) is a sequence in \(\ell_2\) from \(y\in\ell_2\). 
Therefore, \(b\) lies in \(\mathcal{X}_{stab}\).

Proof of \(\ref{enuitem2}\Rightarrow \ref{enuitem3}\):
Claim: $b\in \mathcal{X}_{stab} \doteq \mathcal{R}_{A,B} + \mathcal{X}_A^s \Longrightarrow (A_r,B_r) {\text{ stabilizable}}$.

We prove the statement by contradiction. 
Assume that $ b\in \mathcal{X}_{stab}$ but  $(A_r,B_r)$ not stabilizable. 
Hence, there is \(|\lambda_0| \geq 1\) such that \([\lambda_0 I- A_r,B_r]\) is not full rank. This means that there is a $w\neq 0$ such that
\begin{equation}\label{notstab.eq}
w^\top \begin{bmatrix}\lambda_0 I -A_r&B_r\end{bmatrix}= w^\top \begin{bmatrix}\lambda_0 T_l T_r -T_l A T_r & T_l B\end{bmatrix} = 0
\end{equation}
By the model reduction procedure, we have 
\(w^\top b_r = w^\top T_l b \neq 0,\)
since $[A_r,[B_r,b_r]]$ is reachable by construction. We therefore set \(v^\top = w^\top T_l\) and obtain:
\[
v^\top\begin{bmatrix}
(\lambda_0 I - A)T_r & B 
\end{bmatrix}=0 \quad v^\top b \neq 0.
\]
% From the model reduction procedure, it must be true that \(w^\top b_r = w^\top T_l b\neq 0\), because $[A_r,[B_r,b_r]]$ is reachable by construction.  Now we let $v^\top =w^\top T_l$.
We have $v^\top B=0$. Now consider $v^\top AB$. 
Denote \(v_1^\top = v^\top (\lambda_0 I - A)\), and thus \(v_1^\top T_r = \mathbf{0}\). 
Note that \(v_1^\top\) can be a zero vector.
From $\lambda_0 v^\top-v^\top A=v_1^\top $ it follows that $v^\top A=\lambda_0 v^\top-v_1^\top$ so, $v^\top AB=(\lambda_0 v^\top-v_1^\top)B=0$.

Note that \(v_1^\top T_r = 0 \Rightarrow v_1^\top A B =0\), because the columns of $AB$ are vectors in \({\mathcal R}_{A,B}\) and $T_r$ is a basis for it. Combining with \(v^\top AB =0 \), we get \(v^\top A^2 B = (\lambda_0 v^\top-v_1^\top)AB=0\), therefore \(v^\top A^k B = 0\), which leads to \(v^\top \mathcal{R}_{A,B} = \mathbf{0}\).
 
On the other hand, we have \(v^\top (\lambda_0 I -A) A^{k} b =v_1^\top A^kb =0\), \(\forall k \geq 0\). because $v_1$ is orthogonal to ${\mathcal R}(A,[B,b])$.
We apply the lemma \ref{lm:poly_nonzero_inner_product} to $p
(\lambda)=\psi_A^s(\lambda)$.
Since \(\psi_A^s(\lambda)\) has all the zeros (if any) in the unit circle and \(\lambda_0\) is unstable, then \(\psi_A^s(\lambda_0) \neq 0\). By applying the above lemma, we conclude that \(v^\top \psi_A^s(A) b \neq 0\),  where $v^\top=w^\top T_l$ and $v^\top {\mathcal R}_{A,B}=0$.

For any \(g \in \mathcal{X}_{stab}\), we next show that \(v^\top \psi_A^s(A) g = 0\). \(g\) can be written as \(g = g_s + g_r\), where \(g_s \in \mathcal{X}_A^s, g_r \in \mathcal{R}_{A,B}\). Note that this decomposition is not unique since \(\mathcal{X}_A^s\) might overlap with \(\mathcal{R}_{A,B}\). Because \(\mathcal{X}_A^s\) is defined as the null space of \(\psi_A^s(A)\), \(\psi_A^s(A)\) will annihilate vectors in \(\mathcal{X}_A^s\), \(\psi_A^s(A) g_s =\mathbf{0}\).
From \(g_r \in \mathcal{R}_{A,B}\) and \(\mathcal{R}_{A,B}\) is \(A\)-invariant, \(\psi_A^s(A) g_r \in \mathcal{R}_{A,B}\). But \(v\) is orthogonal to \(\mathcal{R}_{A,B}\), so \(v^\top\psi_A^s(A) g_r = 0\).
\[
v^\top \psi_A^s(A) g = v^\top\psi_A^s(A) (g_s + g_r) =0, \quad \forall g\in  \mathcal{X}_{stab}
\]
Accompanied with \(v^\top \psi_A^s(A) b \neq 0\), we show that \(b\) is not in \(\mathcal{X}_{stab}\), contradictory. Therefore, \((A_r,B_r)\) is stabilizable.


 


Proof of \(\ref{enuitem3} \Rightarrow\ref{enuitem1}\):
Let \(C_r = C T_r\). The affine operator \(\bar{\mathcal{O}}\) can be rewritten as:
\begin{equation}
\begin{split}
    \xi[i+1] & =A_r \xi[i] + B_r u[i] + b_r \delta;\quad \xi[0] =\mathbf{0};\\
    y[i] &= C_r \xi[i] +D u[i]
\end{split}
\end{equation}
In other words, the reduced state-space has the same input-output characteristics as \eqref{eqn:strct_vecss_m}.  
Since \((A_r,B_r)\) is stabilizable, there is \(F\) such that \(A_r+T_l B F\) is Schur. We construct \(u \in \ell_2\) as:
\[
u[i] = \begin{cases}
    \mathbf{0} & i = 0\\
    F (A_r + T_l B F)^{i - 1} T_l b & i \geq 1\\
\end{cases}.
\]
In the reduced state-space, we have \(\xi[1] = b\) instantly.
We can show by induction that \(\xi[i] = (A_r + T_l B F)^{i - 1} T_l b\), which yields:
\[
y[i] = \begin{cases}
    \mathbf{0} & i = 0\\
    (C T_r +D F) (A_r + T_l B F)^{i - 1} T_l b & i \geq 1\\
\end{cases}.
\]
Both \(u,y \in \ell_2\), which concludes the proof. Furthermore, they are also both impulse responses of operators in \(\mathcal{RH}_\infty\).
\end{proof}

Lemma~\ref{lm:delay_stage} amends Theorem~\ref{thm::vecconstraintsoln} that the condition remains true without replacing \(E_i\) with \(E_m\), which essentially means that finite relative order constraints pertain stabilizability. 
\begin{lemma}\label{lm:delay_stage}
The state-space equation \eqref{eqn:strct_vecss} has an input-state-output solution \((u,\eta,q)\in \ell_2\) if and only if \(b_0 \in \mathcal{X}_{stab} \coloneqq \mathcal{R}_{A_v,B_v E_m} + \mathcal{X}_{A_v}^s\).
\end{lemma}
% \begin{proof}
% \(\Rightarrow\) is easy from the fact that \(\mathrm{span}(E_j) \subset \mathrm{span}(E_m)\). We present \(\Leftarrow\) only by constructing a solution \((u,\eta,q)\in \ell_2\).
% Assume (\ref{eqn:strct_vecss_m}) has a solution \((u^\circ,\eta^\circ,q^\circ)\in \ell_2\), then \(\eta^\circ[m] = A_v^{ m-1} b_0 + \sum_{j = 0}^{m - 1} A_v^{ m-1 -j} B_v E_m u^{\circ}[j]\).
% We define the following state-space on \(i\geq m\):
% \begin{equation}\label{eqn:strct_vecss_residue}
% \begin{split}
%     \eta^*[i + 1] &=A_v \eta^*[i] +B_v E_m u^*[i] + b^*\delta[m - 1],\\
%     q^*[i] &= C_v \eta^* [i] +D_v E_m u^*[i];\ \eta^*[m - 1] = \mathbf{0}\\
%     b^* & = \sum_{j = 0}^{m - 1} A_v^{ m-1 -j} B_v E_m u^{\circ} [j]\\
% \end{split}
% \end{equation}
% \(b^*\in \mathcal{X}_{stab}\) follows from lies in \(\mathrm{span}(\mathrm{ctrb}(A_v,B_v E_m))\), we know that (\ref{eqn:strct_vecss_residue}) admits a solution \((u^*,\eta^*,q^*)\in \ell_2\) (defined on \(i\geq m\)) from Theorem \ref{thm::vecconstraintsoln}.
% Now we construct \(u[i] = \mathbf{0}\) for \(i=0, \hdots, m - 1\) and \(u[i] = u^{\circ}[i] - u^*[i]\) for \(i\geq m\) as the input for (\ref{eqn:strct_vecss}). It will produce
% \(\eta[0] = \mathbf{0},\ q[0] = \mathbf{0}\), \(\eta[i + 1] = A_v^{i} b_0,\ q[i] = C_v A_v^{i} b_0\) for \(i=0, \hdots, m - 1\) and \(\eta[i] = \eta^{\circ}[i] - \eta^*[i],\ q[i] = q^{\circ}[i] - q^*[i]\) for \(i > m\).
% Since \(m\) is finite, \(q,\eta\in\ell_2\) follows from that \((u^*,q^*,\eta^*)\in \ell_2\) and \((u^\circ,\eta^\circ,q^\circ)\in \ell_2\).
% \end{proof}

\begin{proof}
($\Leftarrow$) Suppose \(b_0 \in \mathcal{X}_{stab} \).
Given any finite trajectory tuple \((u^\circ, \eta^\circ, q^\circ)\) on horizon \( 0\leq j <m\), it steers the state to \(\eta^\circ[m] = A_v^{m-1} b_0+ \sum_{j=0}^{m-1} A_v^{m-1-j} B_v E_j u^\circ[j]\).
Since \(b_0 \in \mathcal{X}_{stab}\), \(\eta^\circ[m] \in \mathcal{X}_{stab}\).
Consider the following auxiliary state-space starting from \(i = m\):
\begin{equation}\label{eqn:strct_vecss_residue}
\begin{split}
    \eta^*[i+1] &= A_v \eta^*[i] + B_v E_m u^*[i] + b^* \delta_m,\\
    q^*[i] &= C_v \eta^*[i] + D_v E_m u^*[i], \quad \eta^*[m]=0
\end{split}
\end{equation}
with \(b^* \coloneqq A_v \eta^\circ[m]\in \mathcal{X}_{stab}\). From Theorem~\ref{thm::vecconstraintsoln}, \eqref{eqn:strct_vecss_residue} admits a trajectory
$(u^*,\eta^*,q^*)\in \ell_2$ for $i\geq m$.
Now define the input for \eqref{eqn:strct_vecss} by
\[
u[i] = 
\begin{cases}
u^\circ[i], & 0\leq i<m\\
u^*[i], & i\geq m
\end{cases}.
\]
The resulted states and outputs trajectory of \eqref{eqn:strct_vecss} matches:
\[
\eta[i] = \begin{cases}
\eta^\circ[i], & 0\leq i \leq m\\
\eta^*[i], & i > m
\end{cases},
\quad q[i] = \begin{cases}
q^\circ[i], & 0\leq i<m\\
q^*[i], & i\geq m
\end{cases}.
\]
Since $(u^\circ,\eta^\circ,q^\circ)$ is finite horizon and $(u^*,\eta^*,q^*)$ is constructed in $\ell_2$, it follows that $(u,\eta,q)\in \ell_2$.  

($\Rightarrow$): Suppose \((u,\eta,q)\in\ell_2\) satisfies~\eqref{eqn:strct_vecss}. Since $\mathrm{span}(E_j)\subseteq \mathrm{span}(E_m)$ for all $j$, there exists \(\{\bar{u}[j]\}_{0\leq j< m}\) such that \(E_m \bar{u}[j] = E_j u[j]\). Put \(\bar{u}[j] = u[j],\ \forall j \geq m\). Therefore, \(\bar{u} \in \ell_2\) is an input sequence that the state-space~\eqref{eqn:strct_vecss_m} has \(\eta\) and \(y\) trajectories in \(\ell_2\). By Theorem~\ref{thm::vecconstraintsoln}, \(b_0\in \mathcal{X}_{stab}\).
% \begin{equation}\label{eqn:strct_vecss_m}
% \begin{split}
%     \eta[i + 1] &=A_v \eta[i] +B_v E_m u[i] + b_0 \delta;\ \eta[0]=\mathbf{0}\\
%     q[i] &= C_v \eta[i] +D_v E_m u[i]\\
% \end{split}
% \end{equation}
\end{proof}
\begin{rem}
The $\Leftarrow$ case proof provides a constructive method that extends any finite-horizon input sequences into a full infinite-horizon solution to constraint \eqref{eqn:strct_vecss}.
\end{rem}
% \begin{cor}
% Construct \(T_r\) as statement \ref{enuitem3} in Theorem~\ref{thm::vecconstraintsoln}. 
% Let \(A_r = T_l A_v T_r\), \(C_r = C_v T_r\) and \(b = T_l b_0\). For each \(i\leq m\), \(B_r^i = T_l B_v E_i,\ D_i = E_i.\) The state-space
% \begin{equation}\label{eqn::ss::lemmared_xi}
% \begin{split}
%     \xi[i+1] & =A_r \xi[i] + B_r^i u[i] + b \delta; \xi[0] =\mathbf{0};\\
%     q[i] &= C_r \xi[i] +D_i u[i]
% \end{split}
% \end{equation}
% has identical input-output response as \eqref{eqn:strct_vecss}. 
% \end{cor}
% \begin{proof}
% The same as proof of Lemma~\ref{lemma:redsys}.
% \end{proof}




\subsection{Structured stabilization feasibility}

Theorem~\ref{thm:vectimeresp} interprets constraint~\eqref{eqn:mmstructconstr} between Youla parameter \(Q\) and closed-loop \(\Phi\) in time-domain. Building on this, Theorem~\ref{thm::vecconstraintsoln} and Lemma~\ref{lm:delay_stage} jointly characterize the conditions under which time-domain solutions exist. We then consolidate these results in Theorem~\ref{thm::genfea}, which establishes a necessary and sufficient condition for determining the feasibility of structured stabilization within the constrained subspace $\mathcal{S}$. 

% We synthesize Theorem \ref{thm:struct_stab_cont_para}, Theorem \ref{thm::vecconstraintsoln}, and Lemma \ref{lm:delay_stage} into the following Theorem \ref{thm::genfea} that determines the feasibility of {\bf structured stabilization}.

\begin{thm}\label{thm::genfea}
Assume \(\mathcal{S}\) is QI under the plant \(P_{22} = C_y(zI -A)^{-1}B_u\).
There is a stabilizing controller in \(\mathcal{S}\) if and only if the impulse disturbance \(b_0\) lies in the stabilizable subspace of \((A_v,B_v E_m)\), where \([A_v, b_0, B_v]\) are given in (\ref{eqn::ss::vecmat}).
\(E_m\) is uniquely decided by \(\mathcal{S}\).
\end{thm}
% \begin{rem}
% Construct \(T_r, T_l, T_r^\perp, T_l^\perp\) as in Theorem \ref{thm::vecconstraintsoln}.
% \begin{equation*}
%     A_r = T_l A_v T_r;\ B_r^i = T_l B_v E_i;\ C_r = C_v T_r ;\ D_i = E_i;\ b_r = T_l b_0.
% \end{equation*}
% It's then equivalent to find \(\{u\}\in\ell_2\) that generate \(\{q\}\in\ell_2\) in (\ref{eqn::ss::vecPhi_vecQ_red}). 
% \begin{equation}\label{eqn::ss::vecPhi_vecQ_red}
% \begin{split}
%     \zeta[i+1] &=A_r \zeta[i] +B_r^i u[i] +b_r \delta;\ \eta[0]=\mathbf{0}\\
%     q[i] &= C_r \eta[i] +D_i u[i] 
% \end{split}
% \end{equation}
% Since the reduced state-space is closed-loop stabilizable, it's easy to construct rational solutions following Theorem \ref{thm::vecconstraintsoln}.
% \end{rem}

The following corollary simplifies the feasibility condition in Theorem~\ref{thm::genfea} for a special case and reveals its connection to the standard PBH test in centralized control.
\begin{cor}\label{cor:diagA}
Assume \(\mathcal{S}\) is QI under \(P_{22} = C_y(zI -A)^{-1}B_u\), and \(A\) is diagonalizable with distinct eigenvalues, there is a stabilizing controller in \(\mathcal{S}\) if and only if
\[
\left((\nu_\lambda^\top C_y^\top) \otimes (\mu_\lambda^\top B_u)\right) E_m \neq \mathbf{0}
\]
for any unstable eigenvalue \(\lambda\) of \(A\). \(\mu_\lambda\) and \(\nu_\lambda\) are respectively the paired left and right eigenvectors of \(A\) associated with \(\lambda\).
\end{cor}
\begin{rem}
In centralized multivariable control, a stabilizing controller exists if and only if all unstable modes are observable and controllable, as determined by the PBH test. These two conditions can be verified independently, as a centralized controller fully connects all inputs to output channels.

In contrast, sparsity prevents some actuators from accessing some particular sensors, so the structured stabilization criterion must further account for the structure, which is incorporated by \(E_m\). Unsurprisingly, this condition reduces to the PBH test when the graph is strongly connected (\(E_m = I\)).
\end{rem}
\begin{rem}
The structured stabilizability condition in Theorem \ref{thm::genfea} holds for general QI structures and does not rely on the Assumption \ref{ass::samegraph} used in this paper. For instance, it applies to verifying the existence of structured stabilizing controllers in Example~\ref{exp:4nodediamond}.
\end{rem}


When the controller uses the same network as the plant, the equivalent condition for structured stabilization is that each largest strongly connected component, which may consist of several subsystems, is locally detectable and stabilizable \cite{Lessard2012strstab}.
The condition can be easily examined when the local dynamics of all subsystems are defined, by extracting blocks \(A_{ii}, B_{u_{ii}}, C_{y_{ii}}\) from the aggregate realization of the plant.\footnote{When the controller uses a stronger network than the plant, the granularity of the strongly connected component is instead accommodated from the controller topology.}


For instance, consider a plant \(P_{22}\) with partitions \(\mathcal{P}_x = [2,2],\mathcal{P}_y =\mathcal{P}_u = [1,1]\) in \(\mathcal{G}(\mathcal{V}, \mathcal{A})\) with \(\mathcal{V} =\{1,2\}\), \(\mathcal{A} = \begin{bmatrix}
    0 & 0 \\
    1 & 0 \\
\end{bmatrix}\).
The state-space realization of \(P_{22}\) is:
\begin{equation}
    P_{22}= \left[\begin{array}{c|c}
        A & B_u \\
        \hline
        C_y & \mathbf{0}
    \end{array}\right]
    =
    \left[\begin{array}{cccc|cc}
        2 & 0 & 0 & 0 & 1 & 0 \\
        1 & 3 & 0 & 0 & 1 & 0 \\
        0 & 1 & 4 & 0 & 0 & 0 \\
        0 & 0 & 1 & 6 & 0 & 1 \\
        \hline
        1 & 0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 1 & 1 & 0 & 0\\
    \end{array}\right].
\end{equation}
From the controllability and observability test, \((A, B_u, C_y)\) is controllable and observable if given full controller connectivity.
To check the feasibility of structured stabilization from \(K \in \mathfrak{T}(\mathcal{G},\mathcal{P}_u,\mathcal{P}_y)\), find the strongly connected components:
\begin{equation*}
    P_{{22}}^1
    =
    \left[\begin{array}{cc|c}
        2 & 0 & 1 \\
        1 & 3 & 1 \\
        \hline        
        1 & 0 & 0 \\
    \end{array}\right];\ 
    P_{{22}}^2
    =
    \left[\begin{array}{cc|c}
        4 & 0 & 0 \\
        1 & 6 & 1 \\
        \hline        
        1 & 1 & 0 \\
    \end{array}\right].
\end{equation*}
\(P_{{22}}^1\) is not detectable and \(P_{{22}}^2\) is not stabilizable. As a result, there is no \(K \in \mathfrak{T}(\mathcal{G},\mathcal{P}_u,\mathcal{P}_y)\) stabilizes.

In our test, the orthonormal basis \(E_m\) is
\begin{equation}
    E_m = \mathrm{basis} (\vc(\left[\begin{array}{cc}
        \mathbb{R} & 0 \\
        \mathbb{R} & \mathbb{R}
    \end{array}\right]))
    = \left[\begin{array}{ccc}
        1 & 0 & 0 \\
        0 & 1 & 0 \\
        0 & 0 & 0 \\
        0 & 0 & 1
    \end{array}\right].
\end{equation}
Since \(\left((\nu_\lambda^\top C_y^\top) \otimes(\mu_\lambda^\top B_u) \right)E_m = 0\) for the eigenvalues \(\lambda = 3,4\), so their associated mode are not stabilizable through any structured controller.
\begin{rem}
Unlike the locally detectable and stabilizable condition in \cite{Lessard2012strstab}, Theorem~\ref{thm::genfea} and Corollary~\ref{cor:diagA} don't rely on a network-aligned state partition. They can assess structured stabilizability from any stabilizable and detectable realization of the plant.
\end{rem}



% Corollary \ref{cor:diagA} essentially states that every unstable mode must be observable by at least one sensor, controllable by at least one actuator, and the corresponding sensor must be connected to the actuator in the controller network. 









\subsection{Solution and optimal controller recovery}
When \(b_0\) lies in the stabilizable subspace of \((A_v,B_v E_m)\), \((A_r, B_r^m)\) is stabilizable by Theorem~\ref{thm::vecconstraintsoln}.
Problem~\ref{Prob::H2min_ssqp} is a standard infinite-horizon LQR problem. The optimal solution can be explicitly obtained by solving a discrete algebraic Riccati equation (DARE)~\eqref{eqn:vecDARE} for the time-invariant stage for (\(i \geq m\)) and a backward recursion in~\eqref{eqn::backrec} for the time-varying stage from \(i = m - 1\) to \(i = 0\).
\begin{equation}\label{eqn:vecDARE}
\begin{split}
    X_m &= \mathrm{DARE}(A_r, B_r^m, {C_r}^\top \Gamma {C_r}, {D_m}^\top\Gamma D_m,{C_r}^\top \Gamma {D_m},I);\\
    \Theta_m & = {D_{m}}^\top\Gamma D_m + {B_r^m}^\top X_{m}{B_r^m}; \\
    \kappa_m &= -\Theta_m^{-1} ({B_r^m}^\top X_{m} A_r +{D_{m}}^\top\Gamma C_r).\\
\end{split}
\end{equation}
For \(i= m-1,\hdots,0\), the optimal cost-to-go after (exclusive) step \(i\) takes a quadratic form only about state \(\zeta[i+1]\),
\[
J_\mathrm{opt}^{i + 1} = \inf\sum_{j \geq i + 1} v[j]^\top v[j] = \zeta[i + 1]^\top X_{i+1} \zeta[i + 1],
\]
and is produced by the optimal action policy:
\[
u[j] = \left\{ 
\begin{array}{cc}
    \kappa_j \zeta[j], & j = i+1,i+2,\hdots,m-1 \\
    \kappa_m \zeta[j], & j\geq m
\end{array}\right.,
\]
where \(\{X_i\},\{\kappa_i\}\) are matrix sequences recursively defined as:
\begin{equation}\label{eqn::backrec}
\begin{split}
    \Theta_i &= {D_{i}}^\top\Gamma D_i + {B_r^i}^\top X_{i+1}{B_r^i}; \\
    \kappa_i &= -\Theta_i^{-1} ({B_r^i}^\top X_{i+1} A_r +{D_{i}}^\top\Gamma C_r); \\
    X_i &= {C_r}^\top \Gamma {C_r} + {A_r}^\top X_{i+1} A_r - {\kappa_i}^\top \Theta_i \kappa_i. \\
\end{split}
\end{equation}
\(\Theta_i\) is positive-definite for any \(i\) because \(D_i=D_v E_i\) is full column rank and \(\Gamma\) is positive-definite from construction.
At time \(0\), the optimal input explicitly depends on the perturbation \(b_r\):
\begin{equation}\label{eqn::optu0}
u^*[0] = -\Theta_0^{-1} ({B_r^0}^\top X_{1} b_r -{D_{0}}^\top\Gamma \vc(R_0))
\end{equation}














% \begin{equation*}
% \begin{split}
%     R_0 = &\Gamma_b^{-1}(B_u^\top X_b A X_c C_y^\top + D_{zu}^\top C_z X_c C_y^\top \\
%     &+ B_u^\top X_2 B_w D_{yw}^\top +D_{zu}^\top D_{zw} D_{yw}^\top) \Gamma_c^{-1}\\
% \end{split}
% \end{equation*}

% Re-using (\ref{eqn::ss::vecPhi_vecQ_red}), the distributed \(\mathcal{H}_2\) problem is equivalent to an infinite-horizon linear quadratic programming problem.

% {\color{blue}In this infinite-horizon setting, it is standard to assume that the optimal cost-to-go is a quadratic function of the current state, which leads to a discrete algebraic Riccati equation (DARE) for the time-invariant stage and a backward recursion defined on \(i = m-1\hdots,1\) for the time-varying stage derived from the Bellman equation. Solving the DARE and the recursion provides a finite-dimensional, explicit expression for the optimal solution.}

We iteratively recover optimal input sequence \(\{u^*\}\), state sequence \(\{\zeta^*\}\) and output sequence \(\{q^*\}\) from \(u^*[0]\).
\begin{equation}\label{eqn::YPrecovery1}
\begin{split}
    &\zeta^*[1] = B_r^0 u^*[0] + b;\ q^*[0] = D_0 u^*[0];\ \\
    &
    \begin{cases}
        u^*[i] = \kappa_i \zeta^*[i] &  \\
        \zeta^*[i+1] = (A_r + B_r^i \kappa_i)\zeta^*[i] & \\
        q^*[i] = (C_r + D_i \kappa_i)\zeta^*[i] & \\
    \end{cases} ,\ i = 1,\hdots,m-1\\
    &
    \begin{cases}
        u^*[i] = \kappa_m (A_r + B_r^m \kappa_m)^{i-m} \zeta^*[m] &  \\
        \zeta^*[i] = (A_r + B_r^m \kappa_m)^{i-m}\zeta^*[m] & \\
        q^*[i] = (C_r + D_m \kappa_m) (A_r + B_r^m \kappa_m)^{i-m}\zeta^*[m] & \\
    \end{cases},\ i\geq m. 
\end{split}
\end{equation}
\(\{q^*\}\) is a sequence in \(\ell_2\) because \(A_r + B_r^m \kappa_m\) is a Schur matrix from the DARE solution. We construct the TFM of the Youla parameter \(Q\) from its time-domain response:
\begin{equation}\label{eqn::YPrecovery2}
\begin{split}
    \vc(Q_\mathrm{opt}) &= \sum_{i=0}^{m-1} \frac{1}{z^i} q^*[i] \\
    &+ \frac{1}{z^{m-1}}(C_r + D_m \kappa_m) (zI- A_r - B_r^m \kappa_m)^{-1}\zeta^*[m] 
\end{split}
\end{equation}
Finally, we find the optimal controller in \(\mathcal{S}\) with:
\begin{equation}\label{eqn::Krecovery}
\begin{split}
 K_\mathrm{str, opt}& =\lft(J_{YP}, Q_\mathrm{opt}).
 \end{split}
\end{equation}
Algorithm~\ref{alg::optcontroller} provides a structured stabilizing controller TFM. One can follow Theorem~\ref{thm:samegraphReal} to construct the networked implementation of \(K_\mathrm{str, opt}\) when Assumption~\ref{ass::samegraph} is satisfied.

\section{A simplified solution for full-state-feedback problems}

In the special case of state-feedback, the plant is changed into
\begin{equation}
    P = \left[
    \begin{array}{c|cc}
        A & B_w & B_u \\
        \hline
        C_z & D_{zw} & D_{zu}\\
        I & \mathbf{0} & \mathbf{0}
    \end{array}\right]
\end{equation}

\(F,L\) are still chosen to ensure \(A_F,A_L\) are Schur. 
\begin{equation*}
G_{12} = \left[
    \begin{array}{c|c}
        A_F & B_u \\
        \hline
        C_z + D_{zu}F & D_{zu} \\
    \end{array}\right];\ 
G_{21} = \left[
    \begin{array}{c|c}
        A_L & B_w\\
        \hline
        I & \mathbf{0} \\
    \end{array}\right]
\end{equation*}
\begin{equation}
    G_{11} = \left[\begin{array}{cc|c}
    A_F & -B_u F & B_w\\
   \mathbf{0}_{n_x,n_x} & A_L & B_w\\
    \hline
    C_z + D_{zu}F & -D_{zu}F & D_{zw}
\end{array}\right]
\end{equation}

\begin{equation*}
\begin{split}
& G_{11} = \begin{bmatrix}
    C_z+D_{zu} F & -D_{zu} F
\end{bmatrix} \\
& \begin{bmatrix}
    (zI-A_F)^{-1} & -(zI-A_F)^{-1} B_u F (zI-A_L)^{-1} \\
    \mathbf{0} &  (zI-A_L)^{-1}
\end{bmatrix}
\begin{bmatrix}
    B_w \\
    B_w
\end{bmatrix} \\
& = D_{zw} +C_z(zI-A_F)^{-1} B_w  + D_{zu} F(zI-A_F)^{-1} B_w \\
& - C_z (zI-A_F)^{-1} B_u F (zI-A_L)^{-1} B_w \\ 
& - D_{zu} F (zI-A_F)^{-1} B_u F (zI-A_L)^{-1} B_w - D_{zu} F (zI-A_L)^{-1} B_w \\
& = D_{zw} + C_z(zI-A_F)^{-1} B_w  + D_{zu} F(zI-A_F)^{-1} B_w \\
& - C_z (zI-A_F)^{-1} B_u F (zI-A_L)^{-1} B_w \\ 
& - D_{zu} F (zI-A_F)^{-1} (zI -A) (zI-A_L)^{-1} B_w \\ 
& = D_{zw} + C_z(zI-A_F)^{-1} (I - B_u F (zI-A_L)^{-1}) B_w \\
& + D_{zu} F (zI-A_F)^{-1} (I - (zI -A) (zI-A_L)^{-1}) B_w \\
& = D_{zw} + C_z(zI-A_F)^{-1} (zI - A - B_u F - L) (zI-A_L)^{-1} B_w \\
& - D_{zu} F (zI-A_F)^{-1} L (zI-A_L)^{-1} B_w \\
& = D_{zw} + C_z (zI-A_L)^{-1} B_w  \\
& - (C_z + D_{zu} F) (zI-A_F)^{-1} L (zI-A_L)^{-1} B_w
\end{split} 
\end{equation*}
\begin{equation*}
\begin{split}
& G_{12} = (C_z + D_{zu} F) (zI-A_F)^{-1} B_u + D_{zu} \\
& G_{21} = (zI-A_L)^{-1} B_w
\end{split} 
\end{equation*}
We now put \(F\) be the LQR feedback gain for \(P_{12}\) such that \(G_{12}^\sim G_{12} = P_{12}^{\sim} P_{12} = \Gamma_b\). For any stabilizing \(L\) we pick, we notice:
\begin{equation*}
\begin{split}
H_0 = G_{11} + G_{12} F G_{21} = (C_z + D_{zu} F) (zI-A_F)^{-1} B_w + D_{zw}
\end{split} 
\end{equation*}
which achieves the optimal \(\mathcal{H}_2\) performance in standard state-feedback problems. Besides, putting \(L\) equal to \(-A\) bring us huge benefits that \(G_{21} = \frac{1}{z} B_w\) becomes a delayed gain block. By a shift of Youla parameter we should formulate the following optimazation problem, 
\begin{opt}\label{Prob::H2minSF}
\begin{equation}
\begin{split}
    \underset{Q\in\mathcal{RH}_\infty}{\mathrm{minimize}}\ &\|G_{11} - G_{12} Q G_{21}\|_2^2 \\ 
    & = \|H_0\|_2^2 + \|U (Q + F) B_w\|_2^2 \\
    & = \|H_0\|_2^2 + \|\Gamma_b^{1/2} (Q + F) B_w\|_2^2
\end{split}
\end{equation}
subject to
\begin{equation}
    \Phi=(Y_r - M_r Q)\in\mathfrak{T}(\mathcal{G}_c,P_u,P_y)
\end{equation}
\end{opt}
\begin{equation}
\begin{split}
    X[i+1] &=A X[i] + B_u \Phi[i] - A \delta,\\
    Q[i] &= F X[i] - \Phi[i]
\end{split}
\end{equation}
{\color{blue}
\begin{equation}
\begin{split}
    \underset{Q\in\mathcal{RH}_\infty}{\mathrm{minimize}}\ &\|\Gamma_b^{1/2}FB_w + \Gamma_b^{1/2}Q B_w\|_2^2 
\end{split}
\end{equation}
subject to
\begin{equation}
    Q=M_r^{-1}Y_y-M_r^{-1}\Phi;, \Phi\in\mathfrak{T}(\mathcal{G}_c,P_u,P_y)
\end{equation}
Note that \(\mathcal{P}_y = \mathcal{P}_x\) in the state-feedback setting.


$$
\min \|T\Phi B_w\|^2
$$
subject to 
The dynamics associated with $T$
\begin{equation}
T=     \left[
    \begin{array}{c|cc}
        A & -A & B_u \\
        \hline
        -\Gamma_b^{1/2}F & \Gamma_b^{1/2}F & \Gamma_b^{1/2}D_{zu}
    \end{array}\right]
\end{equation}
\begin{equation}
\begin{split}
    X[i+1] &=A X[i] + B_u \Phi[i] - A \delta,\\
    T[i] &=-\Gamma_b^{1/2}F X[i] +\Gamma_b^{1/2}D_{zu}\Phi[i]+\Gamma_b^{1/2}F \delta
\end{split}
\end{equation}
}



\section{Numerical Examples}\label{sec:Exp}


\label{sec::numex}
In Example~\ref{exp::3nodesys}, we provide an illustrative solution and compare our algorithm with an SLS-based solution.
In Example~\ref{exp:4nodediamond}, we use our approach to find optimal controller \(K_\mathrm{opt}\) in \(\mathcal{S}\), where \(\mathcal{S}\) is QI w.r.t the plant but not fitting in Assumption~\ref{ass::samegraph}. We prove that \(K_\mathrm{opt}\) is not realizable on its graph.

\subsection{3-agent distributed control problem}
In Example~\ref{exp::3nodesys} proposed in section II, we let the partition of states, inputs, outputs be \(\mathcal{P}_x =[2;2;2], \mathcal{P}_y = \mathcal{P}_u =[1;1;1]\). Per the controller graph, we want to find optimal controller in the structure set:
\[
\mathcal{S}= \begin{bmatrix}
    \mathcal{R}_p & \frac{1}{z} \mathcal{R}_p & 0 \\
    \frac{1}{z} \mathcal{R}_p & \mathcal{R}_p & 0\\
    \frac{1}{z} \mathcal{R}_p & \frac{1}{z^2}\mathcal{R}_p & \mathcal{R}_p\\
\end{bmatrix}.
\]
We evaluate the generalized plant with:
\begin{equation*}
A = \left[
\begin{array}{cc:cc:cc}
0  &  3.3  & 0 &  -0.4  &  0 &  0 \\
-0.1  &  0.7  &  0.1  & -0.5 &  0 &  0 \\
\hdashline
0 & -0.7 &  0.4 & -0.6  & 0 & 0 \\
-0.4 & 1.7  & 0.6 & -1.6 & 0 & 0 \\
\hdashline
-0.1 &  -1.4  & 0  & 0  &  -0.2  &  0.7 \\
-2.0  & -0.8  & 0 & 0 & 0.3  &  1.1 \\
\end{array}
\right]
\end{equation*}
\begin{equation*}  
B_w = 
\begin{bmatrix}
0.6 & -0.6 & -0.5\\
0.2 & 0.6 & 0.4\\
1 & -1 & -2.2\\
0 & -1 & 0\\
0.3 & 0.5 & 0.2\\
0 & -0.5 & 0.3\\
\end{bmatrix};\  B_u = \left[ \begin{array}{c:c:c}
    0.8 & 0 & 0 \\
    0.5 & 0 & 0\\
    \hdashline
    0 & 0.2 & 0\\
    0 & 0.4 & 0\\
    \hdashline
    0 & 0 & 1 \\
    0 & 0 & -0.4
\end{array}
\right]
\end{equation*}

\begin{equation*}
    C_z = \begin{bmatrix}
    0.1 & 0.4 & 0.1& 0.4& 0.1& 0.4 \\
    0.3 & 0 & 0.5& 1 & 0.6 & 2 \\
    -1 & -0.1 & 0.2 & -0.5 & 0.3 & 1
\end{bmatrix};\
\end{equation*}
\begin{equation*}
C_y = \left[
\begin{array}{cc:cc:cc}
    0.2 & 1 & 0 & -1 & 0 & 0 \\
    \hdashline
    1 & 0 & 0.2 & -1 & 0 & 0\\
    \hdashline
    0 & 1 & 0 & 0 & 0.2 & -1
    \end{array}
\right]
\end{equation*}
\begin{equation}
    D_{zu}^\top  = D_{yw} = \begin{bmatrix}
        I_3
    \end{bmatrix};\     
    D_{zw} = \mathbf{0}_{3\times 3};\ D_{yu} = \mathbf{0}_{3\times 3}.
\end{equation}
% \[
% \left[
% \begin{array}{cc}
% D_{zw} & D_{zu}\\
% D_{yw} & D_{yu}
% \end{array}
% \right]
% =\left[
% \begin{array}{cc}
% \mathbf{0} & I_3\\
% I_3 & \mathbf{0}
% \end{array}
% \right].
% \]

For this plant, the centralized \(\mathcal{H}_2\) gives a norm \(\|G_{11}^0\|_2 = 5.6615\). Our algorithm obtains the optimal controller within \(0.0446s\), with 14 states. We adopt the Theorem~\ref{thm:samegraphReal} to get an implementation with a total of \(25+21+11 = 57\) internal states. The optimal \(\mathcal{H}_2\) norm obtained by a distributed controller is \(\sqrt{\mu_{\mathrm{dis}, \mathcal{H}_2}} = 7.7418\). 
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\linewidth]{figures/DisCtrlfigure/SLSCostvsFIRsteps_3nodeV2.png}
    \caption[Our exact optimal solution and the suboptimal SLS solutions]{The top subplot plots the optimal \(\mathcal{H}_2\) norm obtained by SLS approach, while the bottom subplot plots the value \((\|\cdot\|^2 - \mu_{\mathrm{dis}, \mathcal{H}_2})\) on a logarithm scale.}
    \label{fig:SLScostvsFIR}
\end{figure}
% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=0.85\linewidth]{figures/DisCtrlfigure/SLSvsFIRsteps_3nodeV2.png}
%     \caption{The optimization time consumption and controller states number versus the FIR truncation level.}
%     \label{fig:SLSRuntmevsFIR}
% \end{figure}

In comparison, the SLS approach approximates the optimal controller by designing closed-loop dynamics with FIR truncation levels ranging from 10 to 60 in increments of 5. In this case, FIR solutions exist for the SLS method since \((A,B_u)\) is controllable and \((A,C_y)\) is observable~\cite{SLSparametrization}.
As the FIR horizon increases, the achieved cost gradually converges toward the optimal value.

We find that the controller order grows linearly with the number of FIR steps. The computational time for convex optimization also grows with the number of steps. With 60 steps of FIR, the optimization problem takes \(2.29s\) to solve and gives a controller with 546 states, but the cost is still suboptimal. This trend indicates that while longer FIR horizons improve accuracy, the approximation can never produce the exact optimal closed-loop behavior.

\subsection{4-agent structured control problem}
The state-space representation of the networked plant is provided in Appendix~\ref{appsec:nwss}, along with a detailed walkthrough of its construction from the dynamics of individual sub-plants.
% We walk through the construction of the networked plant in Appendix~\ref{appsec:nwss}.
Rather than searching for controllers in the full space \(\mathfrak{T}(\mathcal{G}^c,\mathcal{P}_{u},\mathcal{P}_y)\),  we further restrict attention to the subset:
\[  
\mathcal{S} = \begin{bmatrix}
0 & \frac{1}{z}\mathcal{R}_p & 0 & \frac{1}{z}\mathcal{R}_p\\
0 & 0 & 0 & 0\\
0 & \frac{1}{z}\mathcal{R}_p & 0 & \frac{1}{z}\mathcal{R}_p\\
0 & 0 & 0 & 0\\
\end{bmatrix}\subset \mathfrak{T}(\mathcal{G}^c,\mathcal{P}_{u},\mathcal{P}_y).
\]
While \(\mathfrak{T}(\mathcal{G}^c,\mathcal{P}_{u},\mathcal{P}_y)\) is not quadratically invariant (QI) with respect to \(P_{22}\), the subset \(\mathcal{S}\) is QI and therefore allows a convex search for stabilizing controllers.
The structure suggests that the networked controller uses only the sensors at nodes \(2\) and \(4\) and the actuators at nodes \(1\) and \(3\), with a unit processing delay from sensing to actuation.
The optimal controller found in \(\mathcal{S}\) is the following:
% \[
% K_\mathrm{opt} = 
% \begin{bmatrix}
% 0 & K_{12} & 0 & K_{14}\\
% 0 & 0 & 0 & 0\\
% 0 & K_{32} & 0 & K_{34}\\
% 0 & 0 & 0 & 0\\
% \end{bmatrix}
% \]
\[
K_\mathrm{opt} = 
[K_{ij}] = 
\begin{cases}
\frac{-0.31887 z (z-0.6332)}{(z+0.9738) (z^2 + 0.4429z + 1.201)}& , ij \in \{12,32,14,34\} \\
0& \text{, Otherwise}
\end{cases}.
\]
% \[
% K_{\chi} = \frac{-0.31887 z (z-0.6332)}{(z+0.9738) (z^2 + 0.4429z + 1.201)}.
% \]

% The optimal CL \(\Phi\) is:
% \[
% \Phi_{\chi} = \frac{-0.31887 (z-0.8)^2 (z-0.6332)}{(z-0.1484) (z+0.1462) (z^2 - 0.181z + 0.06557)}.
% \]
The minimal realization of \(K\) has a pair of complex-conjugate poles, each with multiplicity one. Now we prove that this controller can't be built as the architecture in Fig~\ref{fig:4nodecannot_real}. 
\begin{prop}
    Any realization of \(K\) that conforms to the architecture in Fig.~\ref{fig:4nodecannot_real} doesn't internally stabilize the plant in Example~\ref{exp:4nodediamond}.
\end{prop}
\begin{proof}
Firstly, we denote \(\mathcal{S}^{o} = \mathfrak{T}(\mathcal{G}^c,\mathcal{P}_{u},\mathcal{P}_y)\), which is the set of network distributed systems on the graph \(\mathcal{G}^c(\mathcal{V},\mathcal{A}^c)\):
\[
\mathcal{S}^{o} = 
\begin{bmatrix}
\mathcal{R}_p & \frac{1}{z}\mathcal{R}_p & 0 & \frac{1}{z}\mathcal{R}_p\\
0 & \mathcal{R}_p & 0 & 0\\
0 & \frac{1}{z}\mathcal{R}_p & \mathcal{R}_p & \frac{1}{z}\mathcal{R}_p\\
0 & 0 & 0 & \mathcal{R}_p\\
\end{bmatrix},\quad 
\mathcal{A}^{c} = 
\begin{bmatrix}
0 & 1 & 0 & 1\\
0 & 0 & 0 & 0\\
0 & 1 & 0 & 1\\
0 & 0 & 0 & 0\\
\end{bmatrix}.
\]
Every \(K \in \mathcal{S}\) belongs to \(\mathcal{S}^{o}\). It suffices to show that \(K_\mathrm{opt}\) can't be built on \(\mathcal{G}^c\). 
\(\mathcal{G}^c\) implies the following structured state-space matrices:
\begin{equation*}
    A_c =\begin{bmatrix}
        A_c^{1} & A_c^{12} & \mathbf{0} & A_c^{14} \\
        \mathbf{0} & A_c^{2}& \mathbf{0} & \mathbf{0}\\
        \mathbf{0} & A_c^{32} & A_c^{3} & A_c^{34} \\
        \mathbf{0} & \mathbf{0} & \mathbf{0} & A_c^{4}\\
    \end{bmatrix};\quad
    C_c=\begin{bmatrix}
        C_c^{1} & C_c^{12} & \mathbf{0} & C_c^{14} \\
        \mathbf{0} & C_c^{2}& \mathbf{0} & \mathbf{0}\\
        \mathbf{0} & C_c^{32} & C_c^{3} & C_c^{34} \\
        \mathbf{0} & \mathbf{0} & \mathbf{0} & C_c^{4}\\
    \end{bmatrix};
\end{equation*}
\begin{equation}\label{eqn::4nodereal}
    B_c = \diag[B_{c}^i]; \quad D_{c} = \diag[D_{c}^i].
\end{equation}

Therefore, the TFM of \(K\) can be rewritten as:
\begin{equation}
K = C_c(zI- A_c)^{-1} B_c + D_c =
\begin{bmatrix}
    K_{11} & K_{12} & 0 & K_{14}\\
    0 & K_{22} & 0 & 0\\
    0 & K_{32} & K_{33} & K_{34}\\
    0 & 0 & 0 & K_{44} \\ 
    \end{bmatrix},
\end{equation}
\begin{equation}
    K_{ii} = C_c^{i}(zI- A_c^{i})^{-1}B_c^{i} + D_c^{i}; K_{ij} = C_c^{i}(zI- A_c^{i})^{-1} A_c^{ij} (zI- A_c^{j})^{-1} B_c^{j}.
\end{equation}
Hence, every pole of \(K_{ij}\) is an eigenvalue of either \(A_c^{i}\) or \(A_c^{j}\).
If we group the diagonal blocks of \(A_c\) as \((A_c^{1}, A_c^{2})\) and \((A_c^{3}, A_c^{4})\), the conjugate unstable poles appear in the union of eigenvalues of both \((A_c^{1}, A_c^{2})\) and \((A_c^{3}, A_c^{4})\).
Since the spectrum of \(A_c\) is the union of the spectra of all \(A_c^{i}\), the conjugate unstable poles must have a multiplicity of at least two in \(A_c\).

As a result, any realization structured as in (\ref{eqn::4nodereal}) will violate the internal stability of the  CL interconnection with the plant, since it replicates unstable poles of the feedback controller.
\end{proof}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.25\linewidth]{figures/DisCtrlfigure/node4CtEx_fakeDis.png}
    \caption{The controller collects measurements from vertices \(2,4\) processes them centrally and then assigns control actions to vertices \(1,3\).}
    \label{fig:4nodefakedis}
\end{figure}
In conclusion, the controller cannot be implemented on the network in Fig.~\ref{fig:4nodecannot_real} without violating internal stability. 
Instead, the resulting controller corresponds to the centralized configuration shown in Fig.~\ref{fig:4nodefakedis}. This distinction cannot be captured by transfer functions alone.

\section{Conclusion}

In this paper, we derived the exact finite-dimensional solution to the network-distributed $\mathcal{H}_2$ control problem for an LTI networked plant, assuming that the controller network is at least as well-connected as the plant dynamics. This setup defines a subclass of QI problems that not only satisfies QI conditions but also guarantees the implementability of structured controllers over networks. 

Building on the Youla parameterization initialized by the centralized \(\mathcal{H}_2\) controller, we reformulated the problem as minimizing the cost penalty induced by the imposed structural constraints. By interpreting the constraints in the time domain, we expressed them in a state-space form and evaluated the cost penalty through an associated LQR problem. The exact solution is obtained via an additional DARE and a backward recursion.

To justify our synthesis approach, we also provided a feasibility theorem for structured stabilization. Our algorithm outperforms approximation-based approaches in both computational efficiency and controller order.